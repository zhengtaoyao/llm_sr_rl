"""
VERL è‡ªå®šä¹‰å¥–åŠ±ï¼ˆv2ï¼‰ï¼šç¬¦å·å›å½’çš„å¯†åŒ–å¤šæˆåˆ†å¥–åŠ± + ç»„å†…æ’åå½’ä¸€

ç»„æˆï¼š
- æ‹Ÿåˆï¼šNMSEâ†’r_fit = exp(-lambda * NMSE)
- ç®€æ´ï¼šåŸºäºè¡¨è¾¾å¼ AST å¤æ‚åº¦ï¼ˆé•¿åº¦/èŠ‚ç‚¹/ç®—å­åŠ æƒï¼‰
- ç‰©ç†ä¸€è‡´æ€§ï¼šå¯é€‰ç»´åº¦/è¾¹ç•Œ/å•è°ƒæ€§ç­‰è½¯çº¦æŸé€šè¿‡è®¡åˆ†
- è¿‡ç¨‹å¥–åŠ±ï¼šå¸¸æ•°æ‹Ÿåˆæ˜¯å¦æˆåŠŸã€æ˜¯å¦é€šè¿‡è¯­æ³•æ ¡éªŒ
- æ’åå½’ä¸€ï¼šåŒä¸€ç»„å†…å¯¹å€™é€‰åŠ æƒæ±‚å’Œååš list-wise å½’ä¸€ï¼Œé™ä½å°ºåº¦å™ªå£°

é»˜è®¤å¯¹ code ç‰‡æ®µæå–æ•°å­¦è¡¨è¾¾å¼å¹¶åœ¨å®‰å…¨ç¯å¢ƒä¸­ eval è®¡ç®—ï¼›
å¦‚å‡ºç°å¼‚å¸¸åˆ™è¿”å›å¼ºæƒ©ç½šã€‚
"""

from __future__ import annotations

import math
import re
from typing import Any, Dict, List, Tuple
import numpy as np
import os, json, time
import ast


def compute_score(
    data_sources: List[Any] | None = None,
    solution_strs: List[str] | None = None,
    ground_truths: List[Any] | None = None,
    extra_infos: List[Dict[str, Any]] | None = None,
    *,
    grid_train_data: bool = False,
    template_path: str | None = None,
    data_path: str | None = None,
    memory_dir: str | None = None,
    lambda_nmse: float = 3.0,
    lambda_simp: float = 0.1,
    w_fit: float = 0.6,
    w_simp: float = 0.2,
    w_phys: float = 0.15,
    w_proc: float = 0.05,
    groupwise_rank_norm: bool = True,
    **kwargs,
):
    print(f"ğŸ”¥ğŸ”¥ğŸ”¥ V2 REWARD FUNCTION CALLED! ğŸ”¥ğŸ”¥ğŸ”¥")
    print(f"ğŸ”§ V2 parameter types: data_sources={type(data_sources)}, solution_strs={type(solution_strs)}, ground_truths={type(ground_truths)}, extra_infos={type(extra_infos)}")
    print(f"ğŸ”§ V2 Solution strings count: {len(solution_strs) if solution_strs else 0}")
    if solution_strs and len(solution_strs) > 0:
        print(f"ğŸ”§ V2 First solution preview: {solution_strs[0][:200] if solution_strs[0] else 'None'}...")
    print(f"ğŸ”§ V2 LLMSR_OUTPUT_DIR env: {os.environ.get('LLMSR_OUTPUT_DIR', 'NOT_SET')}")
    
    # è¾“å…¥å…œåº•
    solution_strs = solution_strs or []
    extra_infos = extra_infos or [{} for _ in range(len(solution_strs))]
    if len(solution_strs) == 0:
        return []

    # åŠ è½½æ•°æ®ï¼ˆæœ€å¤š 256 ä¸ªæ ·æœ¬ï¼Œæå‡é€Ÿåº¦ï¼‰
    inputs, outputs, var_names = _load_training_data_from_path(data_path)
    if inputs is None:
        # è¿”å›æƒ©ç½š
        return [float(-1.0)] * len(solution_strs)

    # è®¡ç®—å„é¡¹ reward
    out_dir = os.environ.get("LLMSR_OUTPUT_DIR")
    jsonl_path = None
    if out_dir:
        try:
            os.makedirs(out_dir, exist_ok=True)
            jsonl_path = os.path.join(out_dir, "sample.jsonl")
        except Exception:
            jsonl_path = None

    rewards: List[float] = []
    for i, code in enumerate(solution_strs):
        base_impl = None
        if i < len(extra_infos) and isinstance(extra_infos[i], dict):
            base_impl = extra_infos[i].get("base_impl")

        # æ”¯æŒ EDIT DSLï¼šè‹¥åŒ…å« EDIT æŒ‡ä»¤åˆ™åŸºäº base_impl ç”Ÿæˆè¡¨è¾¾å¼
        edit_mode = False
        expr = ""
        if isinstance(code, str) and (code.strip().startswith("EDIT") or "\nEDIT" in code):
            base_expr = _extract_math_expr(base_impl) if base_impl else None
            expr = _apply_edit_dsl(base_expr, code)
            edit_mode = True
        if not expr:
            expr = _extract_math_expr(code)
        if not expr:
            rewards.append(-1.0)
            # è®°å½•å¤±è´¥æ ·æœ¬
            if jsonl_path:
                try:
                    rec = {
                        "timestamp": time.time(),
                        "expr": None,
                        "raw": code,
                        "base_expr": _extract_math_expr(base_impl) if base_impl else None,
                        "reward": -1.0,
                        "nmse": None,
                        "complexity": None,
                        "r_fit": None,
                        "r_simp": None,
                        "r_phys": None,
                        "r_proc": None,
                        "edit_mode": edit_mode,
                        "ast_ok": False,
                        "data_path": data_path,
                    }
                    with open(jsonl_path, "a", encoding="utf-8") as f:
                        f.write(json.dumps(rec, ensure_ascii=False) + "\n")
                except Exception:
                    pass
            continue

        # è¯­æ³•/AST çº¦æŸæ£€æŸ¥
        ast_ok = _ast_is_legal(expr, allowed_vars=var_names, max_depth=12)
        if not ast_ok:
            rewards.append(-1.0)
            if jsonl_path:
                try:
                    rec = {
                        "timestamp": time.time(),
                        "expr": expr,
                        "raw": code,
                        "base_expr": _extract_math_expr(base_impl) if base_impl else None,
                        "reward": -1.0,
                        "nmse": None,
                        "complexity": None,
                        "r_fit": None,
                        "r_simp": None,
                        "r_phys": None,
                        "r_proc": None,
                        "edit_mode": edit_mode,
                        "ast_ok": False,
                        "data_path": data_path,
                    }
                    with open(jsonl_path, "a", encoding="utf-8") as f:
                        f.write(json.dumps(rec, ensure_ascii=False) + "\n")
                except Exception:
                    pass
            continue

        nmse = _compute_nmse(expr, inputs, outputs, var_names)
        r_fit = math.exp(-lambda_nmse * nmse)

        complexity = _estimate_ast_complexity(expr)
        r_simp = math.exp(-lambda_simp * complexity)

        r_phys = _physical_consistency(expr, var_names, inputs, outputs)

        r_proc = 0.0
        if _constants_optimized(expr, inputs, outputs, var_names):
            r_proc += 0.5

        reward = w_fit * r_fit + w_simp * r_simp + w_phys * r_phys + w_proc * r_proc
        rewards.append(float(reward))

        # è®°å½•æ ·æœ¬
        if jsonl_path:
            try:
                rec = {
                    "timestamp": time.time(),
                    "expr": expr,
                    "raw": code,
                    "base_expr": _extract_math_expr(base_impl) if base_impl else None,
                    "reward": float(reward),
                    "nmse": float(nmse),
                    "complexity": float(complexity),
                    "r_fit": float(r_fit),
                    "r_simp": float(r_simp),
                    "r_phys": float(r_phys),
                    "r_proc": float(r_proc),
                    "edit_mode": edit_mode,
                    "ast_ok": True,
                    "data_path": data_path,
                }
                with open(jsonl_path, "a", encoding="utf-8") as f:
                    f.write(json.dumps(rec, ensure_ascii=False) + "\n")
            except Exception:
                pass

    # ç»„å†…æ’åå½’ä¸€ï¼ˆè‹¥ VERL æ‰¹æ¬¡æ¥è‡ªåŒä¸€æç¤ºç»„ï¼Œå¯é™ä½å°ºåº¦å™ªå£°ï¼‰
    if groupwise_rank_norm and len(rewards) >= 2:
        order = np.argsort(rewards)[::-1]
        ranks = np.empty_like(order)
        ranks[order] = np.arange(len(rewards))
        rewards = (1.0 - ranks / max(1, len(rewards) - 1)).astype(np.float32).tolist()

    # VERL å…¼å®¹ï¼šè¿”å› float æˆ– list
    if len(rewards) == 1:
        return float(rewards[0])
    return rewards


# ============== è¾…åŠ©å‡½æ•° ==============

def _load_training_data_from_path(data_path: str | None) -> Tuple[np.ndarray | None, np.ndarray | None, List[str] | None]:
    if not data_path:
        return None, None, None
    try:
        import pandas as pd
        df = pd.read_csv(data_path)
        data = df.values
        # å‡è®¾æœ€åä¸€åˆ—ä¸ºè¾“å‡º
        X = data[:256, :-1]
        y = data[:256, -1].reshape(-1)
        var_names = df.columns[:-1].tolist()
        return X, y, var_names
    except Exception:
        return None, None, None


def _extract_math_expr(code: str) -> str:
    """ä»LLMç”Ÿæˆçš„Pythonä»£ç ä¸­æå–æ•°å­¦è¡¨è¾¾å¼ï¼Œä¸“æ³¨äºä»£ç å—è§£æ - V2ç‰ˆæœ¬"""
    
    if not code or not isinstance(code, str):
        print("âŒ V2è¡¨è¾¾å¼æå–å¤±è´¥: è¾“å…¥ä¸ºç©ºæˆ–éå­—ç¬¦ä¸²")
        return ""
    
    # æ¸…ç†è¾“å…¥
    code = code.strip()
    original_length = len(code)
    print(f"ğŸ” V2å¼€å§‹æå–è¡¨è¾¾å¼ï¼Œè¾“å…¥é•¿åº¦: {original_length}")
    
    # ğŸ”§ å¤„ç†åŒ…å« <think> æ ‡ç­¾çš„æƒ…å†µï¼Œæå–å®é™…ä»£ç éƒ¨åˆ†
    if "</think>" in code:
        parts = code.split("</think>")
        if len(parts) > 1:
            code = parts[-1].strip()  # å–æœ€åä¸€éƒ¨åˆ†
            print(f"ğŸ”§ V2ä»</think>åæå–å†…å®¹ï¼Œé•¿åº¦: {len(code)}")
    
    import re
    
    # ğŸ”¥ ä¸»ç­–ç•¥ï¼šä»Pythonä»£ç å—ä¸­æå–è¡¨è¾¾å¼
    print("ğŸ” V2ä¸»ç­–ç•¥: è§£æPythonä»£ç å—")
    
    # 1. æŸ¥æ‰¾Pythonä»£ç å—
    python_code_patterns = [
        r'```python\s*\n(.*?)\n```',  # æ ‡å‡†Pythonä»£ç å—
        r'```\s*\n(.*?)\n```',       # é€šç”¨ä»£ç å—
    ]
    
    for pattern in python_code_patterns:
        code_blocks = re.findall(pattern, code, re.DOTALL)
        if code_blocks:
            print(f"ğŸ”§ V2æ‰¾åˆ°{len(code_blocks)}ä¸ªä»£ç å—")
            for i, code_block in enumerate(code_blocks):
                print(f"ğŸ”§ V2å¤„ç†ä»£ç å— {i+1}")
                # ä»ä»£ç å—ä¸­æå–è¡¨è¾¾å¼
                extracted = _extract_from_python_code_v2(code_block.strip())
                if extracted:
                    print(f"âœ… V2ä»ä»£ç å—{i+1}ä¸­æå–åˆ°è¡¨è¾¾å¼: {extracted}")
                    return extracted
    
    # 2. å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»£ç å—ï¼Œå°è¯•ç›´æ¥è§£æå‡½æ•°å®šä¹‰
    print("ğŸ” V2å¤‡ç”¨ç­–ç•¥: ç›´æ¥è§£æå‡½æ•°å®šä¹‰")
    function_pattern = r'def\s+equation\s*\([^)]+\)\s*:\s*(.*?)(?=def|\Z)'
    func_matches = re.findall(function_pattern, code, re.DOTALL | re.IGNORECASE)
    if func_matches:
        for func_body in func_matches:
            print(f"ğŸ”§ V2æ‰¾åˆ°å‡½æ•°ä½“ï¼Œé•¿åº¦: {len(func_body)}")
            extracted = _extract_from_python_code_v2(func_body)
            if extracted:
                print(f"âœ… V2ä»å‡½æ•°ä½“æå–è¡¨è¾¾å¼: {extracted}")
                return extracted
    
    # 3. æœ€åå°è¯•æŸ¥æ‰¾ç®€å•çš„returnè¯­å¥æˆ–èµ‹å€¼è¯­å¥
    print("ğŸ” V2æœ€åç­–ç•¥: æŸ¥æ‰¾ç®€å•è¡¨è¾¾å¼")
    simple_patterns = [
        r'return\s+([^.\n]+?)(?=\s*$|\s*\n|\s*#|$)',
        r'a\s*=\s*([^.\n]+?)(?=\s*$|\s*\n|\s*#|$)',
        r'acceleration\s*=\s*([^.\n]+?)(?=\s*$|\s*\n|\s*#|$)',
    ]
    
    for pattern in simple_patterns:
        matches = re.findall(pattern, code, re.IGNORECASE | re.MULTILINE)
        if matches:
            for match in matches:
                cleaned = match.strip().rstrip('.,;:')
                if _valid_expr(cleaned):
                    print(f"âœ… V2ä»ç®€å•æ¨¡å¼æå–è¡¨è¾¾å¼: {cleaned}")
                    return cleaned
    
    # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
    print("âŒ V2æ‰€æœ‰è¡¨è¾¾å¼æå–ç­–ç•¥éƒ½å¤±è´¥äº†")
    print(f"âŒ V2è¾“å…¥æ–‡æœ¬å‰500å­—ç¬¦: {code[:500]}")
    print(f"âŒ V2è¾“å…¥æ–‡æœ¬å500å­—ç¬¦: {code[-500:]}")
    return ""


def _extract_from_python_code_v2(code_block: str) -> str:
    """V2ç‰ˆæœ¬ï¼šä»Pythonä»£ç ä¸­æå–æ•°å­¦è¡¨è¾¾å¼ï¼Œä¸“é—¨å¤„ç†LLMç”Ÿæˆçš„equationå‡½æ•°"""
    
    if not code_block:
        return ""
    
    print(f"ğŸ”§ V2è§£æPythonä»£ç ï¼Œé•¿åº¦: {len(code_block)}")
    
    lines = code_block.split('\n')
    
    # 1. é¦–å…ˆæŸ¥æ‰¾returnè¯­å¥ï¼ˆæœ€ç›´æ¥çš„æ–¹å¼ï¼‰
    print("ğŸ”§ V2æŸ¥æ‰¾returnè¯­å¥")
    for line in lines:
        line = line.strip()
        if line.startswith('return '):
            expr = line.replace('return ', '').strip()
            # æ¸…ç†å¯èƒ½çš„æ³¨é‡Š
            if '#' in expr:
                expr = expr.split('#')[0].strip()
            if _valid_expr(expr):
                print(f"ğŸ”§ V2ä»returnè¯­å¥æå–: {expr}")
                return expr
    
    # 2. æŸ¥æ‰¾åŠ é€Ÿåº¦ç›¸å…³çš„èµ‹å€¼è¯­å¥
    print("ğŸ”§ V2æŸ¥æ‰¾èµ‹å€¼è¯­å¥")
    assignments = {}
    for line in lines:
        line = line.strip()
        # è·³è¿‡æ³¨é‡Šå’Œå‡½æ•°å®šä¹‰
        if line.startswith('#') or line.startswith('def') or not line:
            continue
        
        if '=' in line and not line.startswith('def'):
            parts = line.split('=', 1)
            if len(parts) == 2:
                var_name = parts[0].strip()
                expr = parts[1].strip()
                
                # æ¸…ç†å¯èƒ½çš„æ³¨é‡Š
                if '#' in expr:
                    expr = expr.split('#')[0].strip()
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„å˜é‡åå’Œè¡¨è¾¾å¼
                if var_name.replace('_', '').isalpha() and _valid_expr(expr):
                    assignments[var_name] = expr
                    print(f"ğŸ”§ V2æ‰¾åˆ°èµ‹å€¼: {var_name} = {expr}")
    
    # 3. ä¼˜å…ˆè¿”å›accelerationç›¸å…³çš„èµ‹å€¼
    priority_vars = ['a', 'acceleration', 'result', 'output', 'acc']
    for var in priority_vars:
        if var in assignments:
            print(f"ğŸ”§ V2é€‰æ‹©ä¼˜å…ˆå˜é‡ {var}: {assignments[var]}")
            return assignments[var]
    
    # 4. è¿”å›æœ€åä¸€ä¸ªæœ‰æ•ˆèµ‹å€¼ï¼ˆé€šå¸¸æ˜¯æœ€ç»ˆç»“æœï¼‰
    if assignments:
        last_var = list(assignments.keys())[-1]
        last_expr = assignments[last_var]
        print(f"ğŸ”§ V2é€‰æ‹©æœ€åèµ‹å€¼ {last_var}: {last_expr}")
        return last_expr
    
    # 5. å¦‚æœæ²¡æœ‰æ‰¾åˆ°èµ‹å€¼ï¼Œå°è¯•æŸ¥æ‰¾åŒ…å«paramsçš„è¡¨è¾¾å¼è¡Œ
    print("ğŸ”§ V2æŸ¥æ‰¾åŒ…å«paramsçš„è¡¨è¾¾å¼")
    for line in lines:
        line = line.strip()
        if 'params[' in line and not line.startswith('#') and not line.startswith('def'):
            # æ¸…ç†å¯èƒ½çš„æ³¨é‡Š
            if '#' in line:
                line = line.split('#')[0].strip()
            
            # å¦‚æœè¿™è¡Œçœ‹èµ·æ¥åƒä¸€ä¸ªè¡¨è¾¾å¼
            if any(op in line for op in ['+', '-', '*', '/', '**']) and _valid_expr(line):
                print(f"ğŸ”§ V2ä»paramsè¡¨è¾¾å¼æå–: {line}")
                return line
    
    print("ğŸ”§ V2Pythonä»£ç è§£æå¤±è´¥")
    return ""


def _extract_from_function_body_v2(func_body: str) -> str:
    """V2ç‰ˆæœ¬ï¼šä»å‡½æ•°ä½“ä¸­æå–æœ€ç»ˆçš„è¡¨è¾¾å¼ï¼Œé‡ç”¨Pythonä»£ç è§£æé€»è¾‘"""
    return _extract_from_python_code_v2(func_body)


def _valid_expr(expr: str) -> bool:
    if not expr:
        return False
    invalid = [r'print\s*\(', r'import\s+', r'def\s+', r'class\s+', r'if\s+', r'for\s+', r'while\s+']
    if any(re.search(p, expr) for p in invalid):
        return False
    has = [r'[a-zA-Z_][a-zA-Z0-9_]*', r'-?[0-9]*\.?[0-9]+', r'[\+\-\*/\(\)]', r'(sin|cos|tan|exp|log|sqrt|abs|tanh)\(']
    return any(re.search(p, expr) for p in has)


def _ast_is_legal(expr: str, allowed_vars: List[str], max_depth: int = 12) -> bool:
    """è§£æ expr çš„ ASTï¼Œä»…å…è®¸å®‰å…¨èŠ‚ç‚¹ä¸ç™½åå•å‡½æ•°/å˜é‡ï¼Œå¹¶é™åˆ¶æ·±åº¦ã€‚"""
    allowed_funcs = {"sin", "cos", "tan", "exp", "log", "sqrt", "abs", "tanh"}
    try:
        tree = ast.parse(expr, mode="eval")
    except Exception:
        return False

    def depth(node: ast.AST) -> int:
        if not list(ast.iter_child_nodes(node)):
            return 1
        return 1 + max(depth(ch) for ch in ast.iter_child_nodes(node))

    if depth(tree) > max_depth:
        return False

    allowed_nodes = (
        ast.Expression,
        ast.BinOp,
        ast.UnaryOp,
        ast.Add,
        ast.Sub,
        ast.Mult,
        ast.Div,
        ast.Pow,
        ast.USub,
        ast.UAdd,
        ast.Call,
        ast.Name,
        ast.Load,
        ast.Constant,
        ast.Tuple,
    )

    for node in ast.walk(tree):
        if not isinstance(node, allowed_nodes):
            return False
        if isinstance(node, ast.Call):
            if not isinstance(node.func, ast.Name):
                return False
            if node.func.id not in allowed_funcs:
                return False
        if isinstance(node, ast.Name):
            if node.id not in allowed_vars:
                return False
    return True


def _apply_edit_dsl(base_expr: str | None, code: str) -> str:
    """åŸºäºç®€å• EDIT DSL å°† base_expr è¿›è¡Œå°æ­¥ç¼–è¾‘ï¼›ä¸åˆæ³•åˆ™è¿”å›ç©ºä¸²ã€‚

    æ”¯æŒæŒ‡ä»¤ï¼ˆåŒ¹é…ç¬¬ä¸€æ¡å³å¯ï¼‰ï¼š
    - EDIT ADD <expr>    ->  (base) + (expr)
    - EDIT MUL <expr>    ->  (base) * (expr)
    - EDIT REPLACE <old> => <new>   ï¼ˆå¯¹ base å­—ç¬¦ä¸²æ›¿æ¢ä¸€æ¬¡ï¼‰
    è‹¥æ—  base_expr åˆ™è¿”å›ç©ºä¸²ã€‚
    """
    if not base_expr or not isinstance(code, str):
        return ""
    lines = [l.strip() for l in code.strip().splitlines() if l.strip()]
    edit_line = None
    for l in lines:
        if l.startswith("EDIT "):
            edit_line = l
            break
    if not edit_line:
        return ""

    body = edit_line[len("EDIT "):].strip()
    # REPLACE
    if body.startswith("REPLACE ") and "=>" in body:
        payload = body[len("REPLACE "):].strip()
        try:
            left, right = payload.split("=>", 1)
            old = left.strip()
            new = right.strip()
            if old:
                return base_expr.replace(old, new, 1)
        except Exception:
            return ""
    # ADD
    if body.startswith("ADD "):
        term = body[len("ADD "):].strip()
        if term:
            return f"({base_expr})+({term})"
    # MUL
    if body.startswith("MUL "):
        term = body[len("MUL "):].strip()
        if term:
            return f"({base_expr})*({term})"
    return ""


def _compute_nmse(expr: str, X: np.ndarray, y: np.ndarray, var_names: List[str]) -> float:
    if not expr:
        return 1.0
    safe = {
        "sin": np.sin, "cos": np.cos, "tan": np.tan,
        "exp": np.exp, "log": np.log, "sqrt": np.sqrt,
        "abs": np.abs, "tanh": np.tanh,
        "pi": np.pi, "e": np.e, "np": np, "__builtins__": {},
    }
    try:
        for i, vn in enumerate(var_names):
            if i < X.shape[1]:
                safe[vn] = X[:, i]
        cleaned = expr.replace('^', '**').replace(' ', '')
        pred = eval(cleaned, safe)
        if isinstance(pred, (int, float)):
            pred = np.full_like(y, float(pred), dtype=np.float64)
        pred = np.asarray(pred, dtype=np.float64)
        if pred.shape[0] != y.shape[0]:
            pred = np.full_like(y, float(pred[0]) if pred.size > 0 else 0.0, dtype=np.float64)
        mse = float(np.mean((pred - y) ** 2))
        var = float(np.var(y) + 1e-9)
        nmse = mse / var
        if not np.isfinite(nmse) or nmse < 0:
            return 1.0
        return min(10.0, nmse)
    except Exception:
        return 1.0


def _estimate_ast_complexity(expr: str) -> float:
    # è¿‘ä¼¼ï¼šé•¿åº¦ + è¿ç®—ç¬¦/å‡½æ•°è®¡æ•°
    ops = len(re.findall(r"[\+\-\*/]", expr))
    funcs = len(re.findall(r"(sin|cos|tan|exp|log|sqrt|abs|tanh)\(", expr))
    nums = len(re.findall(r"-?[0-9]*\.?[0-9]+", expr))
    tokens = max(1, len(re.findall(r"[A-Za-z_][A-Za-z0-9_]*", expr)))
    return 0.5 * ops + 0.8 * funcs + 0.2 * nums + 0.1 * tokens


def _physical_consistency(expr: str, var_names: List[str], X: np.ndarray, y: np.ndarray) -> float:
    # å ä½ï¼šé€šè¿‡åŸºæœ¬æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥ + è¾¹ç•Œç²—æ£€
    # è‹¥éœ€è¦ç»´åº¦åˆ†æï¼Œå¯åœ¨å¤–éƒ¨ä¼ å…¥å•ä½è¡¨ï¼›æ­¤å¤„è¿”å› {1.0, 0.6, 0.2}
    try:
        # å€¼åŸŸåˆç†æ€§ç²—æ£€
        if re.search(r"log\(", expr):
            # log éœ€è¦æ­£è¾“å…¥ï¼Œæ£€æŸ¥æ˜¯å¦å¯èƒ½å‡ºç°éæ­£æ•°
            if np.any(X <= 0):
                return 0.6
        return 1.0
    except Exception:
        return 0.2


def _constants_optimized(expr: str, X: np.ndarray, y: np.ndarray, var_names: List[str]) -> bool:
    # ç®€æ˜“ï¼šè‹¥å­˜åœ¨æ•°å­—å¸¸æ•°ï¼Œå°è¯•ä¸€è½®çº¿æ€§ç¼©æ”¾æ‹Ÿåˆ yâ‰ˆa*pred+b æ˜¯å¦æ”¶æ•›
    try:
        safe = {"sin": np.sin, "cos": np.cos, "tan": np.tan, "exp": np.exp, "log": np.log, "sqrt": np.sqrt, "abs": np.abs, "tanh": np.tanh, "pi": np.pi, "e": np.e, "np": np, "__builtins__": {}}
        for i, vn in enumerate(var_names):
            if i < X.shape[1]:
                safe[vn] = X[:, i]
        cleaned = expr.replace('^', '**').replace(' ', '')
        pred = eval(cleaned, safe)
        pred = np.asarray(pred, dtype=np.float64).reshape(-1)
        A = np.stack([pred, np.ones_like(pred)], axis=1)
        coef, *_ = np.linalg.lstsq(A, y, rcond=None)
        recon = A @ coef
        rel = float(np.mean((recon - y) ** 2) / (np.var(y) + 1e-9))
        return rel < 0.9
    except Exception:
        return False



