"""
GRPO v2 Training Runner for LLM-SR

æœ¬æ–‡ä»¶å®ç°ä¸€ç‰ˆæ›´ç¨³å¥çš„ LLM+GRPOâ†’SR æµç¨‹ï¼ˆv2ï¼‰ï¼š
- å¥–åŠ±å¯†åŒ–ä¸æˆåˆ†åŒ–ï¼šæ‹Ÿåˆ/å¤æ‚åº¦/ç‰©ç†ä¸€è‡´æ€§/è¿‡ç¨‹å¥–åŠ± + ç»„å†…æ’åå½’ä¸€
- è§£ç ä¸åŠ¨ä½œçº¦æŸï¼šæ²¿ç”¨åŸæœ‰éª¨æ¶æ¨¡æ¿ï¼›å¯æ‰©å±•å¸¸æ•°å ä½ç¬¦<C*>ä¸åéªŒæ‹Ÿåˆ
- è®°å¿†ä¸å¤šæ ·æ€§ï¼šè½»é‡â€œå²›å±¿/è®°å¿†åº“â€æ£€ç´¢ few-shotï¼ˆæ–‡ä»¶çº§å…±äº«ï¼Œè·¨è¿›ç¨‹å®‰å…¨ï¼‰
- ç¨³å¥ GRPO é…ç½®ï¼šåŒä¸€æç¤ºç»„å†…é‡‡æ ·ã€æ˜¾å¼ KL æŸå¤±ã€token-mean èšåˆ

è¯´æ˜ï¼šä¸ºé¿å…å¹²æ‰°æ—§å®ç°ï¼Œæ‰€æœ‰é€»è¾‘ç‹¬ç«‹äº v1 æ–‡ä»¶ï¼Œmain.py åˆ†æ”¯è¿›å…¥æœ¬æ–‡ä»¶ã€‚
"""

import os
import sys
import time
from pathlib import Path
from typing import Dict, Any, List

from omegaconf import OmegaConf, DictConfig

# å°† VERL åŠ å…¥è·¯å¾„
verl_path = str(Path(__file__).parent.parent.parent.parent / "verl")
if verl_path not in sys.path:
    sys.path.append(verl_path)

from verl.trainer.main_ppo import run_ppo


# è½»é‡è®°å¿†ç®¡ç†ï¼ˆæ–‡ä»¶å…±äº«ï¼Œè·¨è¿›ç¨‹å®‰å…¨ï¼‰- V2æ”¹è¿›ç‰ˆï¼šè‡ªé€‚åº”åˆ†ä½æ•°åˆ†æ¡¶
class MemoryManagerV2:
    def __init__(self, memory_dir: str, top_k_per_island: int = 8, num_islands: int = 4,
                 update_frequency: int = 50, recent_samples_window: int = 200) -> None:
        os.makedirs(memory_dir, exist_ok=True)
        self._memory_dir = memory_dir  # ğŸ”¥ ä¿å­˜ç›®å½•ç”¨äºåˆ›å»ºç‰ˆæœ¬åŒ–æ–‡ä»¶
        self._path = os.path.join(memory_dir, "memory_v2.json")
        self._history_path = os.path.join(memory_dir, "sample_history.json")  # ğŸ”¥ æ–°å¢ï¼šæ ·æœ¬å†å²
        self._top_k = top_k_per_island
        self._num_islands = num_islands
        self._update_frequency = update_frequency  # æ¯Næ¬¡å†™åº“åé‡æ–°è®¡ç®—åˆ†ä½æ•°
        self._recent_samples_window = recent_samples_window  # æœ€è¿‘Mæ¡æ ·æœ¬ç”¨äºè®¡ç®—åˆ†ä½æ•°
        self._samples_since_update = 0  # è‡ªä¸Šæ¬¡æ›´æ–°åçš„æ ·æœ¬è®¡æ•°
        self._update_version = 0  # ğŸ”¥ æ–°å¢ï¼šç‰ˆæœ¬è®¡æ•°å™¨
        self._samples_since_last_dataset_refresh = 0  # ğŸ”¥ æ–°å¢ï¼šè‡ªä¸Šæ¬¡æ•°æ®é›†åˆ·æ–°åçš„æ–°æ ·æœ¬æ•°
        self._dataset_refresh_threshold = 8  # ğŸ”¥ æ–°å¢ï¼šè§¦å‘æ•°æ®é›†åˆ·æ–°çš„æ–°æ ·æœ¬é˜ˆå€¼

        if not os.path.exists(self._path):
            # åˆå§‹åŒ–ç©ºç»“æ„
            import json
            init = {
                "islands": {str(i): [] for i in range(self._num_islands)},
                "adaptive_thresholds": None,  # ğŸ”¥ è‡ªé€‚åº”é˜ˆå€¼ï¼Œåˆå§‹ä¸ºNoneä½¿ç”¨é»˜è®¤åˆ†æ¡¶
                "last_update_count": 0,
                "version": 0,  # ğŸ”¥ æ–°å¢ï¼šç‰ˆæœ¬å·
                "last_dataset_refresh_version": 0,  # ğŸ”¥ è®°å½•ä¸Šæ¬¡æ•°æ®é›†åˆ·æ–°æ—¶çš„ç‰ˆæœ¬å·
            }
            with open(self._path, "w", encoding="utf-8") as f:
                json.dump(init, f)
        
        # åˆå§‹åŒ–æ ·æœ¬å†å²æ–‡ä»¶
        if not os.path.exists(self._history_path):
            import json
            with open(self._history_path, "w", encoding="utf-8") as f:
                json.dump({"samples": []}, f)

    def load(self) -> Dict[str, Any]:
        import json
        try:
            with open(self._path, "r", encoding="utf-8") as f:
                data = json.load(f)
                # ğŸ”¥ å…¼å®¹æ—§æ ¼å¼ï¼šå¦‚æœæ˜¯æ—§æ ¼å¼ï¼Œè½¬æ¢ä¸ºæ–°æ ¼å¼
                if "islands" not in data:
                    old_data = data
                    data = {
                        "islands": old_data,
                        "adaptive_thresholds": None,
                        "last_update_count": 0,
                        "version": 0,  # ğŸ”¥ æ–°å¢ç‰ˆæœ¬å·
                        "last_dataset_refresh_version": 0  # ğŸ”¥ æ–°å¢æ•°æ®é›†åˆ·æ–°ç‰ˆæœ¬å·
                    }
                # ğŸ”¥ å…¼å®¹ç¼ºå¤±å­—æ®µçš„æƒ…å†µ
                elif "version" not in data:
                    data["version"] = 0
                if "last_dataset_refresh_version" not in data:
                    data["last_dataset_refresh_version"] = 0
                return data
        except Exception:
            return {
                "islands": {str(i): [] for i in range(self._num_islands)},
                "adaptive_thresholds": None,
                "last_update_count": 0,
                "version": 0,  # ğŸ”¥ æ–°å¢ç‰ˆæœ¬å·
                "last_dataset_refresh_version": 0  # ğŸ”¥ æ–°å¢æ•°æ®é›†åˆ·æ–°ç‰ˆæœ¬å·
            }

    def save(self, data: Dict[str, Any], create_versioned_copy: bool = False) -> None:
        """
        ä¿å­˜memoryæ•°æ®
        Args:
            data: è¦ä¿å­˜çš„æ•°æ®
            create_versioned_copy: æ˜¯å¦åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„ç‰ˆæœ¬åŒ–å‰¯æœ¬
        """
        import json
        import time
        from datetime import datetime
        
        # ğŸ”¥ æ›´æ–°ç‰ˆæœ¬å·
        current_version = data.get("version", 0)
        data["version"] = current_version + 1
        self._update_version = data["version"]
        
        # ä¿å­˜ä¸»æ–‡ä»¶
        with open(self._path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        # ğŸ”¥ åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„ç‰ˆæœ¬åŒ–å‰¯æœ¬
        if create_versioned_copy:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            versioned_filename = f"memory_v2_version_{data['version']:04d}_{timestamp}.json"
            versioned_path = os.path.join(self._memory_dir, versioned_filename)
            
            with open(versioned_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ—ƒï¸ åˆ›å»ºç‰ˆæœ¬åŒ–memoryå‰¯æœ¬: {versioned_filename}")
    
    def _load_sample_history(self) -> List[Dict[str, Any]]:
        """åŠ è½½æ ·æœ¬å†å²"""
        import json
        try:
            with open(self._history_path, "r", encoding="utf-8") as f:
                history = json.load(f)
                return history.get("samples", [])
        except Exception:
            return []
    
    def _save_sample_history(self, samples: List[Dict[str, Any]]) -> None:
        """ä¿å­˜æ ·æœ¬å†å²ï¼ˆä¿ç•™æœ€è¿‘Næ¡ï¼‰"""
        import json
        # åªä¿ç•™æœ€è¿‘çš„æ ·æœ¬
        recent_samples = samples[-self._recent_samples_window:] if len(samples) > self._recent_samples_window else samples
        try:
            with open(self._history_path, "w", encoding="utf-8") as f:
                json.dump({"samples": recent_samples}, f, ensure_ascii=False, indent=2)
        except Exception:
            pass
    
    def _compute_adaptive_thresholds(self, samples: List[Dict[str, Any]]) -> Dict[str, float]:
        """åŸºäºæœ€è¿‘æ ·æœ¬è®¡ç®—è‡ªé€‚åº”åˆ†ä½æ•°é˜ˆå€¼"""
        if len(samples) < 20:  # æ ·æœ¬å¤ªå°‘æ—¶ä½¿ç”¨é»˜è®¤é˜ˆå€¼
            return None
        
        import numpy as np
        scores = [s.get("score", 0.0) for s in samples if "score" in s]
        if len(scores) < 10:
            return None
        
        scores = np.array(scores)
        # ğŸ”¥ è®¡ç®—åˆ†ä½æ•°ï¼šP90â†’å²›0(high), P70â†’å²›1(mid-high), P40â†’å²›2(mid), å…¶ä½™â†’å²›3(low)
        try:
            p90 = np.percentile(scores, 90)
            p70 = np.percentile(scores, 70) 
            p40 = np.percentile(scores, 40)
            
            thresholds = {
                "p90": float(p90),  # å²›å±¿0é˜ˆå€¼ï¼ˆhigh qualityï¼‰
                "p70": float(p70),  # å²›å±¿1é˜ˆå€¼ï¼ˆmid-high qualityï¼‰
                "p40": float(p40),  # å²›å±¿2é˜ˆå€¼ï¼ˆmid qualityï¼‰
                # å²›å±¿3ï¼šå‰©ä½™æ ·æœ¬ï¼ˆlow qualityï¼‰
            }
            
            print(f"ğŸï¸ è‡ªé€‚åº”é˜ˆå€¼æ›´æ–°: P90={p90:.3f}, P70={p70:.3f}, P40={p40:.3f}")
            return thresholds
        except Exception as e:
            print(f"âš ï¸ è®¡ç®—è‡ªé€‚åº”é˜ˆå€¼å¤±è´¥: {e}")
            return None

    def sample_few_shot(self, k: int = 3, use_random_sampling: bool = True) -> List[str]:
        """
        ğŸ”¥ V2æ”¹è¿›ç‰ˆï¼šè·¨å²›å±¿é‡‡æ ·å¤šæ ·few-shotï¼Œå¸¦è´¨é‡æ ‡ç­¾/å…ƒä¿¡æ¯
        
        Args:
            k: æœ€å¤§é‡‡æ ·æ•°é‡ï¼ˆå¦‚æœuse_random_sampling=Trueåˆ™å¿½ç•¥ï¼‰
            use_random_sampling: æ˜¯å¦ä½¿ç”¨æ–°çš„éšæœºé‡‡æ ·é€»è¾‘ï¼ˆæ¯ä¸ªå²›å±¿éšæœºä¸€ä¸ªï¼‰
        
        Returns:
            æ ¼å¼åŒ–çš„ç¤ºä¾‹åˆ—è¡¨ï¼ŒåŒ…å«è´¨é‡æ ‡ç­¾å’Œä½¿ç”¨æŒ‡å¯¼
        """
        data = self.load()
        islands = data.get("islands", {})
        examples: List[str] = []
        
        if not islands:
            return examples
        
        quality_levels = ["high", "mid-high", "mid", "low"]
        
        if use_random_sampling:
            # ğŸ”¥ æ–°çš„é‡‡æ ·é€»è¾‘ï¼šä»å››ä¸ªå²›å±¿ä¸­æ¯ä¸ªå²›å±¿éšæœºæŠ½å–ä¸€ä¸ªæ ·æœ¬
            import random
            selected_samples = []
            
            for island_id in range(self._num_islands):
                island_id_str = str(island_id)
                items = islands.get(island_id_str, [])
                
                if not items:
                    continue  # è¯¥å²›å±¿ä¸ºç©ºï¼Œè·³è¿‡
                
                # ğŸ”¥ ä»è¯¥å²›å±¿éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬
                selected_item = random.choice(items)
                
                # ç¡®å®šè´¨é‡ç­‰çº§
                quality = quality_levels[min(island_id, 3)]
                
                impl = selected_item.get("implementation", "")
                if impl:
                    score = selected_item.get("score", 0.0)
                    mse = selected_item.get("mse")
                    complexity = selected_item.get("complexity")
                    
                    # ğŸ”¥ æ„å»ºè´¨é‡æ ‡ç­¾æ³¨é‡Š
                    metadata = f"island={island_id}, quality={quality}, reward={score:.2f}"
                    if mse is not None:
                        metadata += f", mse={mse:.3f}"
                    if complexity is not None:
                        metadata += f", complexity={complexity:.1f}"
                    
                    # ğŸ”¥ æ·»åŠ ä½¿ç”¨æŒ‡å¯¼ï¼ˆæ ¹æ®è´¨é‡çº§åˆ«ï¼‰
                    if quality == "high":
                        guidance = ""  # é«˜è´¨é‡æ ·æœ¬æ— éœ€é¢å¤–æŒ‡å¯¼
                    elif quality == "mid-high":
                        guidance = "  # good pattern, minor refinements may help"
                    elif quality == "mid":
                        guidance = "  # exploratory pattern only; prefer smoother/parsimonious forms"
                    else:  # low quality
                        guidance = "  # counter-example; avoid this pattern; analyze why quality is low"
                    
                    # ğŸ”¥ æ ¼å¼åŒ–ç¤ºä¾‹
                    formatted_example = f"# Example [{metadata}]{guidance}\n{impl.rstrip()}"
                    examples.append(formatted_example)
            
            print(f"ğŸ¯ éšæœºFew-shoté‡‡æ ·å®Œæˆ: {len(examples)}ä¸ªç¤ºä¾‹ï¼Œæ¥è‡ª{len(examples)}ä¸ªä¸åŒå²›å±¿")
            return examples
        
        else:
            # ğŸ”¥ ä¿ç•™åŸæœ‰çš„é‡‡æ ·é€»è¾‘ï¼ˆå…¼å®¹æ€§ï¼‰
            # æ„å»ºæ‰€æœ‰å€™é€‰æ ·æœ¬ï¼ŒæŒ‰å²›å±¿åˆ†ç»„
            all_candidates = []
            
            for island_id, items in islands.items():
                if not items:
                    continue
                
                # ç¡®å®šè´¨é‡ç­‰çº§
                island_idx = int(island_id) if island_id.isdigit() else 3
                quality = quality_levels[min(island_idx, 3)]
                
                # ä¼˜å…ˆscoreé«˜çš„å‰å‡ é¡¹
                items_sorted = sorted(items, key=lambda x: x.get("score", -1.0), reverse=True)
                
                for it in items_sorted[:2]:  # æ¯ä¸ªå²›å±¿æœ€å¤šå–2ä¸ª
                    impl = it.get("implementation", "")
                    if impl:
                        score = it.get("score", 0.0)
                        mse = it.get("mse")
                        complexity = it.get("complexity")
                        
                        # ğŸ”¥ æ„å»ºè´¨é‡æ ‡ç­¾æ³¨é‡Š
                        metadata = f"island={island_id}, quality={quality}, reward={score:.2f}"
                        if mse is not None:
                            metadata += f", mse={mse:.3f}"
                        if complexity is not None:
                            metadata += f", complexity={complexity:.1f}"
                        
                        # ğŸ”¥ æ·»åŠ ä½¿ç”¨æŒ‡å¯¼ï¼ˆæ ¹æ®è´¨é‡çº§åˆ«ï¼‰
                        if quality == "high":
                            guidance = ""  # é«˜è´¨é‡æ ·æœ¬æ— éœ€é¢å¤–æŒ‡å¯¼
                        elif quality == "mid-high":
                            guidance = "  # good pattern, minor refinements may help"
                        elif quality == "mid":
                            guidance = "  # exploratory pattern only; prefer smoother/parsimonious forms"
                        else:  # low quality
                            guidance = "  # counter-example; avoid this pattern; analyze why quality is low"
                        
                        # ğŸ”¥ æ ¼å¼åŒ–ç¤ºä¾‹
                        formatted_example = f"# Example [{metadata}]{guidance}\n{impl.rstrip()}"
                        
                        candidate = {
                            "content": formatted_example,
                            "island": island_idx,
                            "quality": quality,
                            "score": score
                        }
                        all_candidates.append(candidate)
            
            if not all_candidates:
                return examples
            
            # ğŸ”¥ æŒ‰è´¨é‡å’Œåˆ†æ•°æ’åºï¼šé«˜è´¨é‡åœ¨å‰ï¼ŒåŒè´¨é‡å†…æŒ‰åˆ†æ•°æ’åº
            all_candidates.sort(key=lambda x: (x["island"], -x["score"]))
            
            # ğŸ”¥ ä¼˜å…ˆé€‰æ‹©é«˜è´¨é‡ç¤ºä¾‹ï¼Œç¡®ä¿å¤šæ ·æ€§
            selected = []
            
            # é¦–å…ˆå°½é‡é€‰æ‹©é«˜è´¨é‡æ ·æœ¬ï¼ˆå²›å±¿0å’Œ1ï¼‰
            high_quality = [c for c in all_candidates if c["island"] <= 1]
            selected.extend(high_quality[:max(1, k//2)])
            
            # ç„¶åæ·»åŠ ä¸­ç­‰è´¨é‡æ ·æœ¬ä¿æŒå¤šæ ·æ€§
            mid_quality = [c for c in all_candidates if c["island"] > 1]
            remaining = k - len(selected)
            if remaining > 0:
                selected.extend(mid_quality[:remaining])
            
            # æå–å†…å®¹
            examples = [c["content"] for c in selected[:k]]
            
            print(f"ğŸ¯ Few-shoté‡‡æ ·å®Œæˆ: {len(examples)}ä¸ªç¤ºä¾‹ï¼Œè´¨é‡åˆ†å¸ƒ: {[c['quality'] for c in selected[:k]]}")
            return examples
    
    def add_sample(self, function_body: str, score: float, mse: float = None, complexity: float = None) -> bool:
        """
        ğŸ”¥ V2æ”¹è¿›ç‰ˆï¼šæ·»åŠ ä¼˜ç§€æ ·æœ¬åˆ°è®°å¿†åº“ï¼ˆè‡ªé€‚åº”åˆ†ä½æ•°åˆ†æ¡¶ï¼‰
        
        Returns:
            bool: æ˜¯å¦éœ€è¦åˆ·æ–°æ•°æ®é›†ï¼ˆå½“æ–°æ ·æœ¬æ•°>=8æ—¶ï¼‰
        """
        if not function_body or score < 0.1:  # è¿‡æ»¤ä½è´¨é‡æ ·æœ¬
            return False
        
        try:
            data = self.load()
            islands = data.get("islands", {})
            adaptive_thresholds = data.get("adaptive_thresholds")
            
            # ğŸ”¥ åŸºäºè‡ªé€‚åº”é˜ˆå€¼é€‰æ‹©ç›®æ ‡å²›å±¿
            if adaptive_thresholds and all(k in adaptive_thresholds for k in ["p90", "p70", "p40"]):
                # ä½¿ç”¨è‡ªé€‚åº”åˆ†ä½æ•°é˜ˆå€¼
                if score >= adaptive_thresholds["p90"]:
                    target_island = "0"  # é«˜è´¨é‡å²›å±¿ï¼ˆP90ä»¥ä¸Šï¼‰
                elif score >= adaptive_thresholds["p70"]:
                    target_island = "1"  # ä¸­é«˜è´¨é‡å²›å±¿ï¼ˆP70-P90ï¼‰
                elif score >= adaptive_thresholds["p40"]:
                    target_island = "2"  # ä¸­è´¨é‡å²›å±¿ï¼ˆP40-P70ï¼‰
                else:
                    target_island = "3"  # ä½è´¨é‡å²›å±¿ï¼ˆP40ä»¥ä¸‹ï¼‰
            else:
                # å…œåº•ï¼šä½¿ç”¨å›ºå®šé˜ˆå€¼ï¼ˆå‘åå…¼å®¹ï¼‰
                if score >= 0.8:
                    target_island = "0"
                elif score >= 0.5:
                    target_island = "1"
                elif score >= 0.3:
                    target_island = "2"
                else:
                    target_island = "3"
            
            # æ„å»ºæ ·æœ¬è®°å½•
            sample = {
                "implementation": function_body,
                "score": float(score),
                "mse": float(mse) if mse is not None else None,
                "complexity": float(complexity) if complexity is not None else None,
                "timestamp": time.time()
            }
            
            # æ·»åŠ åˆ°ç›®æ ‡å²›å±¿
            if target_island not in islands:
                islands[target_island] = []
            
            islands[target_island].append(sample)
            
            # ä¿æŒæ¯ä¸ªå²›å±¿æœ€å¤štop_kä¸ªæ ·æœ¬ï¼ˆæŒ‰scoreæ’åºï¼‰
            islands[target_island] = sorted(islands[target_island], key=lambda x: x.get("score", 0), reverse=True)[:self._top_k]
            
            # ğŸ”¥ æ›´æ–°æ ·æœ¬å†å²
            sample_history = self._load_sample_history()
            sample_history.append(sample)
            self._save_sample_history(sample_history)
            
            # ğŸ”¥ æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°è‡ªé€‚åº”é˜ˆå€¼
            self._samples_since_update += 1
            create_version = False  # ğŸ”¥ æ–°å¢ï¼šæ˜¯å¦åˆ›å»ºç‰ˆæœ¬åŒ–å‰¯æœ¬
            
            if self._samples_since_update >= self._update_frequency:
                recent_samples = sample_history[-self._recent_samples_window:] if len(sample_history) > self._recent_samples_window else sample_history
                new_thresholds = self._compute_adaptive_thresholds(recent_samples)
                if new_thresholds:
                    data["adaptive_thresholds"] = new_thresholds
                    create_version = True  # ğŸ”¥ é˜ˆå€¼æ›´æ–°æ—¶åˆ›å»ºç‰ˆæœ¬
                data["last_update_count"] = len(sample_history)
                self._samples_since_update = 0
                print(f"ğŸ”„ å·²è§¦å‘è‡ªé€‚åº”é˜ˆå€¼æ›´æ–°ï¼ŒåŸºäº{len(recent_samples)}ä¸ªæœ€è¿‘æ ·æœ¬")
            
            # æ›´æ–°æ•°æ®ç»“æ„
            data["islands"] = islands
            
            # ğŸ”¥ å¢åŠ æ–°æ ·æœ¬è®¡æ•°
            self._samples_since_last_dataset_refresh += 1
            
            # ğŸ”¥ æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°æ•°æ®é›†ï¼ˆåŸºäºæ–°æ ·æœ¬æ•°ï¼‰
            last_refresh_version = data.get("last_dataset_refresh_version", 0)
            current_version = data.get("version", 0)
            
            # è®¡ç®—è‡ªä¸Šæ¬¡åˆ·æ–°ä»¥æ¥çš„ç‰ˆæœ¬å·®å¼‚ï¼ˆè¿‘ä¼¼ä¸ºæ–°æ ·æœ¬æ•°çš„æŒ‡æ ‡ï¼‰
            version_diff = current_version - last_refresh_version
            need_refresh = self._samples_since_last_dataset_refresh >= self._dataset_refresh_threshold
            
            if need_refresh:
                print(f"ğŸ”„ è¾¾åˆ°æ•°æ®é›†åˆ·æ–°é˜ˆå€¼ï¼šæ–°æ ·æœ¬æ•°={self._samples_since_last_dataset_refresh} >= {self._dataset_refresh_threshold}")
                # ğŸ”¥ è®°å½•åˆ·æ–°æ—¶çš„ç‰ˆæœ¬å·ï¼Œé‡ç½®è®¡æ•°å™¨
                data["last_dataset_refresh_version"] = current_version + 1  # +1å› ä¸ºä¸‹é¢ä¼šå†å¢åŠ ç‰ˆæœ¬å·
                self._samples_since_last_dataset_refresh = 0
                create_version = True  # å¼ºåˆ¶åˆ›å»ºç‰ˆæœ¬åŒ–å‰¯æœ¬
            
            # ğŸ”¥ ä¿å­˜æ›´æ–°åçš„æ•°æ®ï¼Œåœ¨é‡è¦æ›´æ–°æ—¶åˆ›å»ºç‰ˆæœ¬åŒ–å‰¯æœ¬
            self.save(data, create_versioned_copy=create_version)
            
            threshold_info = ""
            if adaptive_thresholds:
                threshold_info = f" (è‡ªé€‚åº”é˜ˆå€¼: P90={adaptive_thresholds['p90']:.3f})"
            
            refresh_info = f" [è§¦å‘æ•°æ®é›†åˆ·æ–°]" if need_refresh else ""
            print(f"âœ… æˆåŠŸæ·»åŠ æ ·æœ¬åˆ°å²›å±¿{target_island}ï¼Œscore: {score:.3f}{threshold_info}{refresh_info}")
            
            return need_refresh
            
        except Exception as e:
            print(f"âš ï¸ æ·»åŠ æ ·æœ¬åˆ°memoryå¤±è´¥: {e}")
            return False
    

    
    def get_island_stats(self) -> Dict[str, Any]:
        """
        ğŸ”¥ è·å–ç¾¤å²›ç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äºç›‘æ§ï¼‰
        """
        data = self.load()
        islands = data.get("islands", {})
        stats = {
            "version": data.get("version", 0),
            "total_samples": sum(len(items) for items in islands.values()),
            "islands_info": {}
        }
        
        quality_levels = ["high", "mid-high", "mid", "low"]
        for island_id, items in islands.items():
            island_idx = int(island_id) if island_id.isdigit() else 3
            quality = quality_levels[min(island_idx, 3)]
            
            if items:
                scores = [item.get("score", 0.0) for item in items]
                stats["islands_info"][island_id] = {
                    "quality": quality,
                    "count": len(items),
                    "avg_score": sum(scores) / len(scores),
                    "max_score": max(scores),
                    "min_score": min(scores)
                }
            else:
                stats["islands_info"][island_id] = {
                    "quality": quality,
                    "count": 0,
                    "avg_score": 0.0,
                    "max_score": 0.0,
                    "min_score": 0.0
                }
        
        return stats





def _extract_prompt_header(spec_text: str) -> str:
    lines = spec_text.split("\n")
    prompt_lines: List[str] = []
    in_evolve = False
    for line in lines:
        if "@equation.evolve" in line:
            in_evolve = True
            continue
        if in_evolve and line.strip().startswith("def "):
            prompt_lines.append(line.rstrip())
            break
        if not in_evolve:
            prompt_lines.append(line.rstrip())
    return "\n".join(prompt_lines).strip()


def refresh_dataset_with_islands(
    dataset_path: str,
    template_path: str,
    data_path: str,
    memory_dir: str,
    output_dir: str,
    grid_train_data: bool = False,
    num_grid_groups: int = 10,
    few_shot_k: int = 3,
    num_islands: int = 4,
    top_k_per_island: int = 8,
) -> str:
    """
    ğŸ”¥ æ–°å¢ï¼šåŠ¨æ€åˆ·æ–°æ•°æ®é›†ï¼Œä»ç¾¤å²›ä¸­é‡æ–°é‡‡æ ·few-shot exampleså¹¶ç”Ÿæˆæ–°çš„æ•°æ®é›†
    
    Args:
        dataset_path: ç°æœ‰æ•°æ®é›†è·¯å¾„
        template_path: æ¨¡æ¿æ–‡ä»¶è·¯å¾„
        data_path: åŸå§‹æ•°æ®è·¯å¾„
        memory_dir: ç¾¤å²›memoryç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        å…¶ä»–å‚æ•°: ä¸create_llmsr_dataset_v2ç›¸åŒ
        
    Returns:
        æ–°æ•°æ®é›†æ–‡ä»¶è·¯å¾„
    """
    import pandas as pd
    import pyarrow as pa
    import pyarrow.parquet as pq
    from datetime import datetime
    
    print(f"ğŸ”„ å¼€å§‹åˆ·æ–°æ•°æ®é›†ï¼Œä»ç¾¤å²›é‡æ–°é‡‡æ ·few-shot examples...")
    
    # ğŸ”¥ ä»ç¾¤å²›ä¸­é‡æ–°é‡‡æ ·few-shot examplesï¼ˆä½¿ç”¨éšæœºé‡‡æ ·ï¼‰
    memory = MemoryManagerV2(memory_dir, top_k_per_island=top_k_per_island, num_islands=num_islands)
    examples = memory.sample_few_shot(k=few_shot_k, use_random_sampling=True)
    
    if not examples:
        print(f"âš ï¸ ç¾¤å²›ä¸­æ²¡æœ‰æ ·æœ¬ï¼Œä¿æŒåŸæ•°æ®é›†ä¸å˜")
        return dataset_path
    
    # ğŸ”¥ é‡æ–°æ„å»ºå¸¦few-shotçš„prompt
    with open(template_path, "r", encoding="utf-8") as f:
        spec_text = f.read()
    base_prompt = _extract_prompt_header(spec_text)
    
    # ğŸ”¥ æ·»åŠ æŠ¤æ è¯´æ˜ï¼ˆè‹±æ–‡ï¼‰
    guardrail_instruction = """
# === Few-shot Examples from Memory (Quality-Guided) ===
# PRIORITY GUIDANCE: 
# - Follow examples marked as "quality=high" primarily
# - Examples with "quality=mid-high" show good patterns with minor refinements needed
# - Examples with "quality=mid" are exploratory only; prefer smoother/parsimonious forms
# - Examples with "quality=low" are counter-examples; analyze why quality is low and avoid similar patterns
# - Focus on mathematical correctness, simplicity, and numerical stability
"""
    
    # ğŸ”¥ æ ¼å¼åŒ–few-shotå—
    few_shot_content = guardrail_instruction + "\n" + "\n\n".join(examples)
    few_shot_block = few_shot_content
    composed_prompt = (base_prompt + few_shot_block).strip()
    
    # ğŸ”¥ è¯»å–åŸæœ‰æ•°æ®é›†çš„æ•°æ®éƒ¨åˆ†ï¼ˆä¿æŒç›¸åŒçš„æ•°æ®åˆ†å¸ƒï¼‰
    try:
        # å°è¯•è¯»å–åŸå§‹parquetæ–‡ä»¶çš„æ•°æ®
        original_table = pq.read_table(dataset_path)
        original_data = original_table.to_pylist()
        
        print(f"âœ… ä»åŸæ•°æ®é›†è¯»å–{len(original_data)}æ¡è®°å½•")
        
        # ğŸ”¥ æ›´æ–°æ¯æ¡è®°å½•çš„promptéƒ¨åˆ†
        updated_entries = []
        for entry in original_data:
            # ä¿æŒåŸæœ‰çš„ç³»ç»Ÿæ¶ˆæ¯
            original_prompt = entry.get("prompt", [])
            if len(original_prompt) >= 2:
                system_msg = original_prompt[0]  # ä¿æŒç³»ç»Ÿæ¶ˆæ¯ä¸å˜
                # æ›´æ–°ç”¨æˆ·æ¶ˆæ¯ä¸ºæ–°çš„few-shot prompt
                updated_prompt = [
                    system_msg,
                    {"role": "user", "content": composed_prompt}
                ]
                entry["prompt"] = updated_prompt
            
            updated_entries.append(entry)
        
        # ğŸ”¥ ç”Ÿæˆæ–°çš„æ•°æ®é›†æ–‡ä»¶ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        new_dataset_path = os.path.join(output_dir, f"llmsr_train_v2_refreshed_{timestamp}.parquet")
        
        table = pa.Table.from_pylist(updated_entries)
        pq.write_table(table, new_dataset_path)
        
        print(f"âœ… æ•°æ®é›†åˆ·æ–°å®Œæˆ: {new_dataset_path}")
        print(f"ğŸ¯ æ–°few-shotæ ·æœ¬æ•°: {len(examples)}")
        
        return new_dataset_path
        
    except Exception as e:
        print(f"âŒ æ•°æ®é›†åˆ·æ–°å¤±è´¥: {e}")
        # å¦‚æœå¤±è´¥ï¼Œé‡æ–°åˆ›å»ºæ•°æ®é›†
        print(f"ğŸ”„ å›é€€åˆ°é‡æ–°åˆ›å»ºæ•°æ®é›†...")
        return create_llmsr_dataset_v2(
            template_path=template_path,
            data_path=data_path,
            output_dir=output_dir,
            memory_dir=memory_dir,
            grid_train_data=grid_train_data,
            num_grid_groups=num_grid_groups,
            few_shot_k=few_shot_k,
            num_islands=num_islands,
            top_k_per_island=top_k_per_island,
        )


def create_llmsr_dataset_v2(
    template_path: str,
    data_path: str,
    output_dir: str,
    memory_dir: str,
    grid_train_data: bool = False,
    num_grid_groups: int = 10,
    few_shot_k: int = 3,
    # ğŸï¸ ç¾¤å²›æœºåˆ¶è¶…å‚æ•°
    num_islands: int = 4,           # ç¾¤å²›æ•°é‡
    top_k_per_island: int = 8,      # æ¯ä¸ªå²›å±¿ä¿å­˜çš„topæ ·æœ¬æ•°
) -> str:
    import pandas as pd
    import numpy as np
    from sklearn.preprocessing import KBinsDiscretizer
    import pyarrow as pa
    import pyarrow.parquet as pq

    with open(template_path, "r", encoding="utf-8") as f:
        spec_text = f.read()
    base_prompt = _extract_prompt_header(spec_text)

    # ğŸ”¥ V2æ”¹è¿›ç‰ˆï¼šfew-shot æ‹¼æ¥ + æŠ¤æ æç¤ºï¼ˆè‹±æ–‡ï¼‰- ä½¿ç”¨éšæœºé‡‡æ ·
    memory = MemoryManagerV2(memory_dir, top_k_per_island=top_k_per_island, num_islands=num_islands)
    examples = memory.sample_few_shot(k=few_shot_k, use_random_sampling=True)
    
    if examples:
        # ğŸ”¥ æ·»åŠ æŠ¤æ è¯´æ˜ï¼ˆè‹±æ–‡ï¼‰
        guardrail_instruction = """
# === Few-shot Examples from Memory (Quality-Guided) ===
# PRIORITY GUIDANCE: 
# - Follow examples marked as "quality=high" primarily
# - Examples with "quality=mid-high" show good patterns with minor refinements needed
# - Examples with "quality=mid" are exploratory only; prefer smoother/parsimonious forms
# - Examples with "quality=low" are counter-examples; analyze why quality is low and avoid similar patterns
# - Focus on mathematical correctness, simplicity, and numerical stability
"""
        
        # ğŸ”¥ æ ¼å¼åŒ–few-shotå—
        few_shot_content = guardrail_instruction + "\n" + "\n\n".join(examples)
        few_shot_block = few_shot_content
    else:
        few_shot_block = ""
    
    composed_prompt = (base_prompt + few_shot_block).strip()

    df = pd.read_csv(data_path)
    max_samples = len(df)

    # Grid-based samplingï¼ˆæŒ‰é—®é¢˜è‡ªåŠ¨æ£€æµ‹è¾“å…¥/è¾“å‡ºåˆ—ï¼‰
    if grid_train_data:
        input_cols: List[str] = []
        output_col: str | None = None
        if "oscillator" in data_path:
            input_cols = [c for c in ["x", "v"] if c in df.columns] or df.columns[:-1].tolist()
            output_col = "a" if "a" in df.columns else df.columns[-1]
        elif "bactgrow" in data_path:
            input_cols = [c for c in ["b", "s", "temp", "pH"] if c in df.columns] or df.columns[:-1].tolist()
            output_col = "db" if "db" in df.columns else df.columns[-1]
        elif "stressstrain" in data_path:
            input_cols = [c for c in ["strain", "temp"] if c in df.columns] or df.columns[:-1].tolist()
            output_col = "stress" if "stress" in df.columns else df.columns[-1]
        else:
            input_cols = df.columns[:-1].tolist()
            output_col = df.columns[-1]

        # 1D/2D/ND åˆ†æ¡¶
        if len(input_cols) == 1:
            discretizer = KBinsDiscretizer(n_bins=num_grid_groups, encode="ordinal", strategy="uniform")
            df["grid_group"] = discretizer.fit_transform(df[input_cols].values)
        elif len(input_cols) == 2:
            import math
            nbin = int(max(1, round(math.sqrt(num_grid_groups))))
            dx = KBinsDiscretizer(n_bins=nbin, encode="ordinal", strategy="uniform")
            dy = KBinsDiscretizer(n_bins=nbin, encode="ordinal", strategy="uniform")
            gx = dx.fit_transform(df[[input_cols[0]]].values)
            gy = dy.fit_transform(df[[input_cols[1]]].values)
            df["grid_group"] = gx * nbin + gy
        else:
            from sklearn.cluster import KMeans
            kmeans = KMeans(n_clusters=num_grid_groups, random_state=42)
            df["grid_group"] = kmeans.fit_predict(df[input_cols].values)

        df["grid_group"] = df["grid_group"].astype(int)
        samples_per_group = max(1, max_samples // num_grid_groups)
        parts = []
        for gid in range(num_grid_groups):
            sub = df[df["grid_group"] == gid]
            if len(sub) == 0:
                continue
            parts.append(sub.sample(n=min(samples_per_group, len(sub)), random_state=42))
        df_s = pd.concat(parts).reset_index(drop=True)
    else:
        df_s = df.sample(n=min(max_samples, len(df)), random_state=42).reset_index(drop=True)
        df_s["grid_group"] = 0

    # è‡ªåŠ¨æ£€æµ‹è¾“å…¥/è¾“å‡ºåˆ—
    input_cols: List[str] = []
    output_col: str | None = None
    
    # æ ¹æ®é—®é¢˜ç±»å‹è‡ªåŠ¨æ£€æµ‹è¾“å…¥/è¾“å‡ºåˆ—
    if "oscillator" in data_path:
        input_cols = [c for c in ["x", "v"] if c in df_s.columns] or df_s.columns[:-1].tolist()
        output_col = "a" if "a" in df_s.columns else df_s.columns[-1]
    elif "bactgrow" in data_path:
        input_cols = [c for c in ["b", "s", "temp", "pH"] if c in df_s.columns] or df_s.columns[:-1].tolist()
        output_col = "db" if "db" in df_s.columns else df_s.columns[-1]
    elif "stressstrain" in data_path:
        input_cols = [c for c in ["strain", "temp"] if c in df_s.columns] or df_s.columns[:-1].tolist()
        output_col = "stress" if "stress" in df_s.columns else df_s.columns[-1]
    else:
        # é»˜è®¤ï¼šå‡è®¾æœ€åä¸€åˆ—æ˜¯è¾“å‡ºï¼Œå…¶ä½™æ˜¯è¾“å…¥
        input_cols = df_s.columns[:-1].tolist()
        output_col = df_s.columns[-1]
    
    print(f"ğŸ¯ æ£€æµ‹åˆ°è¾“å…¥åˆ—: {input_cols}, è¾“å‡ºåˆ—: {output_col}")

    # ç»„è£… VERL æ•°æ®
    dataset_entries: List[Dict[str, Any]] = []
    for i in range(len(df_s)):
        row = df_s.iloc[i]
        
        # ğŸ”¥ æå–çœŸå®çš„ ground truth å€¼ï¼ˆCSVä¸­çš„å› å˜é‡å€¼ï¼‰
        ground_truth_value = float(row[output_col]) if output_col in row else None
        
        # å¢åŠ  system çº¦æŸè¯´æ˜ï¼›user ä¸­æ”¾å…¥è§„èŒƒ + few-shot
        system_prefix = (
            "You generate equation skeletons under grammar/AST constraints.\n"
            "- Prefer valid mathematical expressions over prose.\n"
            "- Optionally use EDIT DSL to modify a provided base expression.\n"
            "EDIT Usage: 'EDIT ADD <expr>' | 'EDIT MUL <expr>' | 'EDIT REPLACE <old> => <new>'\n"
            "Return final Pythonic expression or a minimal function body."
        )
        chat_prompt = [
            {"role": "system", "content": system_prefix},
            {"role": "user", "content": composed_prompt},
        ]

        entry = {
            "prompt": chat_prompt,
            "data_source": "llm_sr_train_v2",
            "reward_model": {
                "style": "rule",
                # ğŸ”¥ æ­£ç¡®ä½¿ç”¨CSVä¸­çš„å› å˜é‡å€¼ä½œä¸ºground truth
                "ground_truth": ground_truth_value
            },
            "extra_info": {
                "grid_group": int(row["grid_group"]),
                # è®°å½•åŸå§‹æ•°æ®ç‚¹ç”¨äºæ½œåœ¨ç‰©ç†ä¸€è‡´æ€§ä¸è¿‡ç¨‹å¥–åŠ±
                "data_point": row.drop("grid_group").to_dict(),
                # è®°å½•è¾“å…¥/è¾“å‡ºåˆ—ä¿¡æ¯
                "input_cols": input_cols,
                "output_col": output_col,
                # å¯é€‰ä¼ é€’åŸºåº•è¡¨è¾¾å¼ï¼ˆç”±åç»­ç®¡çº¿å¡«å……ï¼‰ï¼Œç”¨äº EDIT æ¨¡å¼
                "base_impl": None,
            },
        }
        dataset_entries.append(entry)

    table = pa.Table.from_pylist(dataset_entries)
    out_path = os.path.join(output_dir, "llmsr_train_v2.parquet")
    pq.write_table(table, out_path)
    return out_path


def create_llmsr_reward_file_v2(
    template_path: str, 
    data_path: str, 
    output_dir: str, 
    memory_dir: str, 
    grid_train_data: bool = False,
    length_penalty_alpha: float = 0.03,
    parse_bonus: float = 0.1,
    invalid_penalty: float = -0.5,
    enable_physics_reward: bool = False,
    enable_process_reward: bool = True,  # ğŸ”¥ æ–°å¢è¿‡ç¨‹å¥–åŠ±å¼€å…³
    # ğŸï¸ ç¾¤å²›æœºåˆ¶è¶…å‚æ•°
    num_islands: int = 4,           # ç¾¤å²›æ•°é‡
    top_k_per_island: int = 8,      # æ¯ä¸ªå²›å±¿ä¿å­˜çš„topæ ·æœ¬æ•°
    # ğŸ”¥ æ•°æ®é›†åˆ·æ–°å‚æ•°
    refresh_manager_config: Dict[str, Any] = None,  # æ•°æ®é›†åˆ·æ–°ç®¡ç†å™¨é…ç½®
) -> str:
    # ğŸ”¥ ç”Ÿæˆåˆ·æ–°ç®¡ç†å™¨é…ç½®å­—ç¬¦ä¸²
    refresh_config_str = "None"
    if refresh_manager_config:
        refresh_config_str = repr(refresh_manager_config)
    
    code = f'''"""
Wrapper for v2 reward to plug into VERL custom_reward_function.
"""
import sys
import os
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent.parent))
from llmsr.rl.simple_verl_reward_v2_fixed import compute_score as compute_score_v2

# ğŸ”¥ è®¾ç½®è¾“å‡ºç›®å½•ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿sample.jsonlå†™å…¥æ­£ç¡®ä½ç½®
os.environ["LLMSR_OUTPUT_DIR"] = "{output_dir}"

def compute_score(data_sources=None, solution_strs=None, ground_truths=None, extra_infos=None, **kwargs):
    return compute_score_v2(
        data_sources=data_sources,
        solution_strs=solution_strs,
        ground_truths=ground_truths,
        extra_infos=extra_infos,
        grid_train_data={grid_train_data},
        template_path="{template_path}",
        data_path="{data_path}",
        memory_dir="{memory_dir}",
        length_penalty_alpha={length_penalty_alpha},
        parse_bonus={parse_bonus},
        invalid_penalty={invalid_penalty},
        enable_physics_reward={enable_physics_reward},
        enable_process_reward={enable_process_reward},
        num_islands={num_islands},
        top_k_per_island={top_k_per_island},
        refresh_manager_config={refresh_config_str},
        **kwargs
    )
'''
    out = os.path.join(output_dir, "llmsr_reward_v2.py")
    with open(out, "w", encoding="utf-8") as f:
        f.write(code)
    return out


def create_grpo_config_v2(
    model_path: str,
    dataset_path: str,
    reward_file_path: str,
    output_dir: str,
    *,
    gpus: int = 8,
    rollout_n: int = 4,
    kl_coef: float = 1e-3,
    max_prompt_length: int = 4096,  # ğŸ”¥ å¢åŠ åˆ°4096
    max_new_tokens: int = 8192,     # ğŸ”¥ å¢åŠ åˆ°8192
    max_model_len: int = 16384,     # ğŸ”¥ å¢åŠ åˆ°16384
    max_num_batched_tokens: int = 8192,  # ğŸ”¥ å¢åŠ åˆ°8192
    learning_rate: float = 1e-6,
    epochs: int = 5,
) -> DictConfig:
    # token é•¿åº¦å®‰å…¨é˜ˆå€¼
    safe_max_token_len = max(16384, int(max_prompt_length + max_new_tokens + 512))  # ğŸ”¥ å¢åŠ åˆ°16384
    micro_bsz_per_gpu = 1
    traj_micro_bsz = micro_bsz_per_gpu * gpus
    traj_mini_bsz = max(2, traj_micro_bsz * 2)
    prompt_mini_bsz = traj_mini_bsz * rollout_n
    prompt_bsz = prompt_mini_bsz

    cfg = {
        "algorithm": {
            "_target_": "verl.trainer.config.AlgoConfig",
            "adv_estimator": "grpo",
            "gamma": 1.0,
            "lam": 1.0,
            "norm_adv_by_std_in_grpo": True,
            "use_kl_in_reward": False,
            "kl_penalty": "kl",
            "use_pf_ppo": False,
            "pf_ppo": {
                "reweight_method": "pow",
                "weight_pow": 2.0
            },
            "kl_ctrl": {
                "_target_": "verl.trainer.config.KLControlConfig",
                "type": "fixed", 
                "kl_coef": float(kl_coef), 
                "horizon": 10000, 
                "target_kl": 0.1
            },
        },
        "data": {
            "tokenizer": None,
            "use_shm": False,
            "train_files": [dataset_path],
            "val_files": [dataset_path],
            "prompt_key": "prompt",
            "reward_fn_key": "data_source",
            "max_prompt_length": max_prompt_length,
            "max_response_length": max_new_tokens,
            "train_batch_size": prompt_bsz,
            "val_batch_size": prompt_mini_bsz,
            "return_raw_input_ids": False,
            "return_raw_chat": False,
            "return_full_prompt": False,
            "shuffle": True,
            "dataloader_num_workers": 8,
            "validation_shuffle": False,
            "filter_overlong_prompts": True,
            "filter_overlong_prompts_workers": 1,
            "truncation": "error",
            "image_key": "images",
            "video_key": "videos",
            "trust_remote_code": False,
            "custom_cls": {
                "path": None,
                "name": None
            },
            "return_multi_modal_inputs": True,
            # ğŸ”§ é¿å… Missing key data.sampler
            "sampler": {
                "class_path": None,
                "class_name": None
            },
            "datagen": {
                "path": None,
                "name": None
            },
            "apply_chat_template_kwargs": {}
        },
        "actor_rollout_ref": {
            "model": {
                "path": model_path,
                "use_remove_padding": True,
                "enable_gradient_checkpointing": True,
                "use_fused_kernels": False,
                "trust_remote_code": False,
                "custom_chat_template": None,
                "external_lib": None,
                "override_config": {},
                "enable_activation_offload": False,
                "lora_rank": 0,
                "lora_alpha": 16,
                "target_modules": "all-linear",
                "exclude_modules": None,
                "use_liger": False,
                "fused_kernel_options": {}
            },
            "actor": {
                "_target_": "verl.workers.config.FSDPActorConfig",
                "strategy": "fsdp",
                "optim": {
                    "_target_": "verl.workers.config.FSDPOptimizerConfig",
                    "lr": learning_rate, 
                    "weight_decay": 0.01,
                    "lr_warmup_steps_ratio": 0.0,
                    "total_training_steps": -1,
                    "lr_warmup_steps": -1,
                    "min_lr_ratio": 0.0,
                    "num_cycles": 0.5,
                    "warmup_style": "constant"
                },
                "ppo_mini_batch_size": prompt_mini_bsz,
                "ppo_micro_batch_size": None,
                "ppo_micro_batch_size_per_gpu": micro_bsz_per_gpu,
                "use_kl_loss": True,
                "kl_loss_coef": float(kl_coef),
                "kl_loss_type": "low_var_kl",
                "entropy_coeff": 0.0,
                "clip_ratio": 0.2,
                "clip_ratio_low": 0.2,
                "clip_ratio_high": 0.2,
                "clip_ratio_c": 3.0,
                "ppo_epochs": 1,
                "loss_agg_mode": "token-mean",  # å¤„ç†é•¿åº¦åç½®
                "use_dynamic_bsz": True,
                "ulysses_sequence_parallel_size": 1,
                "ppo_max_token_len_per_gpu": safe_max_token_len,
                "use_remove_padding": True,
                "use_fused_kernels": False,
                "use_torch_compile": False,
                "entropy_checkpointing": False,
                "grad_clip": 1.0,
                "shuffle": False,
                "policy_loss": {
                    "_target_": "verl.workers.config.PolicyLossConfig",
                    "loss_mode": "vanilla",
                    "clip_cov_ratio": 0.0002,
                    "clip_cov_lb": 1.0,
                    "clip_cov_ub": 5.0,
                    "kl_cov_ratio": 0.0002,
                    "ppo_kl_coef": 0.1
                },
                "fsdp_config": {
                    "_target_": "verl.workers.config.FSDPEngineConfig",
                    "fsdp_size": gpus,
                    "param_offload": True,
                    "optimizer_offload": True,
                    "forward_prefetch": False,
                    "offload_policy": False,
                    "reshard_after_forward": True,
                    "wrap_policy": {"min_num_params": 0},
                },
                "checkpoint": {
                    "_target_": "verl.trainer.config.CheckpointConfig",
                    "save_contents": ["model", "optimizer", "extra"], 
                    "load_contents": ["model", "optimizer", "extra"],
                    "async_save": False
                },
                "profiler": {
                    "_target_": "verl.utils.profiler.ProfilerConfig",
                    "tool": None,
                    "enable": False,
                    "all_ranks": False,
                    "ranks": [],
                    "save_path": None,
                    "tool_config": {
                        "nsys": {
                            "_target_": "verl.utils.profiler.config.NsightToolConfig",
                            "discrete": False
                        },
                        "torch": {
                            "_target_": "verl.utils.profiler.config.TorchProfilerToolConfig",
                            "step_start": -1,
                            "step_end": -1
                        },
                        "torch_memory": {
                            "_target_": "verl.utils.profiler.config.TorchMemoryToolConfig",
                            "trace_alloc_max_entries": 100000,
                            "stack_depth": 32
                        },
                        "npu": {
                            "_target_": "verl.utils.profiler.config.NPUToolConfig",
                            "contents": [],
                            "level": "level1",
                            "analysis": False,
                            "discrete": False
                        }
                    },
                    "global_tool_config": None
                },
            },
            "rollout": {
                "_target_": "verl.workers.config.RolloutConfig",
                "name": "vllm",
                "mode": "sync",
                "n": rollout_n,
                "temperature": 0.7,  # ğŸ”¥ é™ä½æ¸©åº¦å‡å°‘é‡å¤
                "top_p": 0.95,       # ğŸ”¥ å¢åŠ top_pæé«˜å¤šæ ·æ€§
                "top_k": 50,         # ğŸ”¥ å¢åŠ top_k
                "do_sample": True,
                "over_sample_rate": 0,
                "prompt_length": max_prompt_length,
                "response_length": max_new_tokens,
                "dtype": "bfloat16",
                "gpu_memory_utilization": 0.6,
                "ignore_eos": False,
                "enforce_eager": True,
                "cudagraph_capture_sizes": None,
                "free_cache_engine": True,
                "tensor_model_parallel_size": 1,
                "max_num_batched_tokens": max_num_batched_tokens,
                "max_model_len": max_model_len,
                "max_num_seqs": 1024,
                "log_prob_micro_batch_size": None,
                "log_prob_micro_batch_size_per_gpu": micro_bsz_per_gpu,
                "log_prob_use_dynamic_bsz": True,
                "log_prob_max_token_len_per_gpu": safe_max_token_len,
                "disable_log_stats": False,
                "multi_stage_wake_up": False,
                "engine_kwargs": {
                    "vllm": {},  # ğŸ”¥ penaltyå‚æ•°å·²ç§»åˆ°rollouté…ç½®ä¸­
                    "sglang": {}
                },
                "calculate_log_probs": False,
                "agent": {
                    "_target_": "verl.workers.config.AgentLoopConfig",
                    "num_workers": 8,
                    "agent_loop_config_path": None,
                    "custom_async_server": {
                        "_target_": "verl.workers.config.CustomAsyncServerConfig",
                        "path": None,
                        "name": None
                    }
                },
                "trace": {
                    "_target_": "verl.workers.config.TraceConfig",
                    "backend": None,
                    "token2text": False
                },
                "update_weights_bucket_megabytes": 512,
                "skip_rollout": False,
                "skip_dump_dir": "/tmp/rollout_dump",
                "profiler": {
                    "_target_": "verl.utils.profiler.ProfilerConfig",
                    "tool": None,
                    "enable": False,
                    "all_ranks": False,
                    "ranks": [],
                    "save_path": None,
                    "tool_config": {
                        "nsys": {
                            "_target_": "verl.utils.profiler.config.NsightToolConfig",
                            "discrete": False
                        }
                    },
                    "global_tool_config": None
                },
                "enable_chunked_prefill": False,
                "load_format": "auto",
                "layered_summon": False,
                "layer_name_map": {},
                "val_kwargs": {
                    "_target_": "verl.workers.config.SamplingConfig",
                    "do_sample": True, 
                    "temperature": 0.7,  # ğŸ”¥ é™ä½æ¸©åº¦å‡å°‘é‡å¤
                    "top_p": 0.95,       # ğŸ”¥ å¢åŠ top_pæé«˜å¤šæ ·æ€§
                    "top_k": 50,         # ğŸ”¥ å¢åŠ top_k
                    "n": 1  # ğŸ”¥ CRITICAL: éªŒè¯æ—¶é‡‡æ ·æ•°é‡å¿…é¡»ä¸º1
                },
                # ğŸ”¥ CRITICAL: æ·»åŠ ç¼ºå¤±çš„rolloutå­—æ®µ (v2æ¨¡å¼)
                "calculate_log_probs": False,  # ç”¨äºè°ƒè¯•çš„rolloutæ¦‚ç‡è®°å½•
                "free_cache_engine": True,  # ç”Ÿæˆåé‡Šæ”¾KVç¼“å­˜å¼•æ“
                "ignore_eos": False,
                "over_sample_rate": 0,
                "multi_stage_wake_up": False,
                "engine_kwargs": {
                    "vllm": {},  # ğŸ”¥ penaltyå‚æ•°å·²ç§»åˆ°rollouté…ç½®ä¸­
                    "sglang": {}
                },
                "update_weights_bucket_megabytes": 512,
                "trace": {
                    "_target_": "verl.workers.config.TraceConfig",
                    "backend": None,
                    "token2text": False
                },
                "skip_rollout": False,
                "skip_dump_dir": "/tmp/rollout_dump",
                "profiler": {
                    "_target_": "verl.utils.profiler.ProfilerConfig",
                    "tool": None,
                    "enable": False,
                    "all_ranks": False,
                    "ranks": [],
                    "save_path": None,
                    "tool_config": {
                        "nsys": {
                            "_target_": "verl.utils.profiler.config.NsightToolConfig",
                            "discrete": False
                        }
                    },
                    "global_tool_config": None
                },
                "enable_chunked_prefill": False,
                "load_format": "auto",
                "layered_summon": False,
                "layer_name_map": {},
                "multi_turn": {
                    "_target_": "verl.workers.config.MultiTurnConfig",
                    "enable": False, 
                    "max_assistant_turns": None, 
                    "tool_config_path": None, 
                    "max_user_turns": None,
                    "max_parallel_calls": 1,
                    "max_tool_response_length": 256,
                    "tool_response_truncate_side": "middle",
                    "interaction_config_path": None,
                    "use_inference_chat_template": False, 
                    "tokenization_sanity_check_mode": "strict", 
                    "format": "hermes"
                },
            },
            "ref": {
                "log_prob_micro_batch_size": None,
                # ğŸ”¥ CRITICAL: refæ¨¡å‹å¿…é¡»æœ‰æ­£ç¡®çš„å¾®æ‰¹é‡å¤§å° (ä¸èƒ½ä¸º0!)
                "log_prob_micro_batch_size_per_gpu": micro_bsz_per_gpu,
                # ğŸ”¥ CRITICAL: æ·»åŠ ç¼ºå¤±çš„ ulysses_sequence_parallel_size å­—æ®µ
                "ulysses_sequence_parallel_size": 1,  # ä¸ actor ä¿æŒä¸€è‡´
                "log_prob_use_dynamic_bsz": True,
                # å‚è€ƒæ¨¡å‹ log_prob çš„æœ€å¤§ token é•¿åº¦åŒæ ·ä½¿ç”¨å®‰å…¨é˜ˆå€¼
                "log_prob_max_token_len_per_gpu": safe_max_token_len,
                # ğŸ”¥ æ·»åŠ  DataParallelPPOActor éœ€è¦çš„å…¶ä»–å­—æ®µ
                "use_remove_padding": True,  # ä¸ actor ä¿æŒä¸€è‡´
                "use_fused_kernels": False,  # ç¦ç”¨èåˆå†…æ ¸
                "entropy_from_logits_with_chunking": False,
                "use_torch_compile": False,
                "entropy_checkpointing": False,
                "grad_clip": 1.0,  # æ¢¯åº¦è£å‰ªï¼Œå³ä½¿refä¸ä¼˜åŒ–ä¹Ÿéœ€è¦
                "fsdp_config": {
                    "_target_": "verl.workers.config.FSDPEngineConfig",
                    "fsdp_size": gpus, 
                    "param_offload": True, 
                    "optimizer_offload": True,
                    "forward_prefetch": False,  # ğŸ”¥ ç¦ç”¨å‰å‘é¢„å–ä»¥èŠ‚çœå†…å­˜
                    "offload_policy": False,
                    "reshard_after_forward": True,
                    "wrap_policy": {"min_num_params": 0}
                },
            },
            "hybrid_engine": True,
        },
        "critic": {
            "_target_": "verl.workers.config.FSDPCriticConfig",
            "enable": True,  # ğŸ”§ ä¿®å¤ Missing key critic.enable
            "strategy": "fsdp",
            "rollout_n": rollout_n,
            "ppo_mini_batch_size": prompt_mini_bsz,
            "ppo_micro_batch_size": None,
            "ppo_micro_batch_size_per_gpu": micro_bsz_per_gpu,
            "use_dynamic_bsz": True,
            "forward_micro_batch_size": None,
            "forward_micro_batch_size_per_gpu": micro_bsz_per_gpu,
            "ulysses_sequence_parallel_size": 1,
            "grad_clip": 1.0,
            "optim": {
                "_target_": "verl.workers.config.FSDPOptimizerConfig",
                "lr": learning_rate,
                "weight_decay": 0.01,
                "lr_warmup_steps_ratio": 0.0,
                "total_training_steps": -1,
                "lr_warmup_steps": -1,
                "min_lr_ratio": None,
                "warmup_style": "constant"
            },
            "model": {
                "_target_": "verl.workers.config.FSDPCriticModelCfg",
                "path": model_path,
                "tokenizer_path": model_path,
                "override_config": {},
                "external_lib": None,
                "trust_remote_code": False,
                "use_shm": False,
                "enable_gradient_checkpointing": True,
                "enable_activation_offload": False,
                "use_remove_padding": True,
                "lora_rank": 0,
                "lora_alpha": 16,
                "target_modules": "all-linear",
                "fsdp_config": {
                    "_target_": "verl.workers.config.FSDPEngineConfig",
                    "param_offload": True,
                    "optimizer_offload": True,
                    "offload_policy": False,
                    "reshard_after_forward": True,
                    "wrap_policy": {"min_num_params": 0},
                    "fsdp_size": gpus,
                    "forward_prefetch": False
                }
            },
            "ppo_epochs": 1,
            "shuffle": False,
            "cliprange_value": 0.5,
            "loss_agg_mode": "token-mean",
            "ppo_max_token_len_per_gpu": safe_max_token_len,
            "forward_max_token_len_per_gpu": safe_max_token_len,
            "checkpoint": {
                "_target_": "verl.trainer.config.CheckpointConfig",
                "save_contents": ["model", "optimizer", "extra"],
                "load_contents": ["model", "optimizer", "extra"],
                "async_save": False
            },
            "profiler": {
                "_target_": "verl.utils.profiler.ProfilerConfig",
                "tool": None,
                "enable": False,
                "all_ranks": False,
                "ranks": [],
                "save_path": None,
                "tool_config": {
                    "nsys": {
                        "_target_": "verl.utils.profiler.config.NsightToolConfig",
                        "discrete": False
                    },
                    "torch": {
                        "_target_": "verl.utils.profiler.config.TorchProfilerToolConfig",
                        "step_start": -1,
                        "step_end": -1
                    },
                    "torch_memory": {
                        "_target_": "verl.utils.profiler.config.TorchMemoryToolConfig",
                        "trace_alloc_max_entries": 100000,
                        "stack_depth": 32
                    },
                    "npu": {
                        "_target_": "verl.utils.profiler.config.NPUToolConfig",
                        "contents": [],
                        "level": "level1",
                        "analysis": False,
                        "discrete": False
                    }
                },
                "global_tool_config": None
            },

        },
        "reward_model": {"enable": False, "launch_reward_fn_async": False},
        "custom_reward_function": {"path": reward_file_path, "name": "compute_score"},
        "trainer": {
            "total_epochs": epochs,
            "total_training_steps": None,
            "project_name": "llm_sr_grpo_v2",
            "experiment_name": "direct_weight_tuning_v2",
            "logger": ["console", "wandb"],
            "n_gpus_per_node": gpus,
            "nnodes": 1,
            "save_freq": 2,
            "test_freq": 5,
            "val_before_train": True,
            "default_local_dir": output_dir,
            "device": "cuda",
            "resume_mode": "disable",
            "critic_warmup": 0,
            "balance_batch": True,
            "log_val_generations": 10,
            "log_train_generations": 5,
            "profile_steps": None,
            "default_hdfs_dir": None,
            "log_prob_max_token_len_per_gpu": safe_max_token_len,
            
            # ğŸ”§ æ·»åŠ ç¼ºå¤±çš„ ESI é…ç½®é¡¹
            "esi_redundant_time": 0.0,
            "esi_enable": False,
        },
        "ray_kwargs": {
            "ray_init": {
                "num_cpus": None,
                "runtime_env": {
                    "env_vars": {
                        "PYTHONPATH": os.environ.get("LOCAL_PYTHON_PATH", "/storage/home/westlakeLab/zhangjunlei/llm_sr_rl/verl:/storage/home/westlakeLab/zhangjunlei/llm_sr_rl/LLM-SR")
                    }
                }
            }
        },
        "global_profiler": {
            "_target_": "verl.utils.profiler.ProfilerConfig",
            "tool": None,
            "steps": None,
            "profile_continuous_steps": False,
            "save_path": "outputs/profile",
            "global_tool_config": {
                "nsys": {
                    "_target_": "verl.utils.profiler.config.NsightToolConfig",
                    "discrete": False
                },
                "torch_memory": {
                    "trace_alloc_max_entries": 100000,
                    "stack_depth": 32,
                    "context": "all",
                    "stacks": "all",
                    "kw_args": {}
                }
            }
        },
    }
    return OmegaConf.create(cfg)


def train_llmsr_grpo_v2(
    template_path: str,
    data_path: str,
    model_path: str,
    output_dir: str,
    *,
    grid_train_data: bool = False,
    num_grid_groups: int = 10,
    gpus: int = 8,
    rollout_n: int = 4,
    kl_coef: float = 1e-3,
    max_prompt_length: int = 4096,  # ğŸ”¥ å¢åŠ åˆ°4096
    max_new_tokens: int = 8192,     # ğŸ”¥ å¢åŠ åˆ°8192
    max_model_len: int = 16384,     # ğŸ”¥ å¢åŠ åˆ°16384
    max_num_batched_tokens: int = 8192,  # ğŸ”¥ å¢åŠ åˆ°8192
    learning_rate: float = 1e-6,
    epochs: int = 5,
    few_shot_k: int = 3,
    # ğŸï¸ ç¾¤å²›æœºåˆ¶è¶…å‚æ•°
    num_islands: int = 4,           # ç¾¤å²›æ•°é‡
    top_k_per_island: int = 8,      # æ¯ä¸ªå²›å±¿ä¿å­˜çš„topæ ·æœ¬æ•°
    # ğŸ”¥ æ–°å¢é•¿åº¦æƒ©ç½šå’Œè§£æå¥–åŠ±å‚æ•°
    length_penalty_alpha: float = 0.03,  # é•¿åº¦æƒ©ç½šç³»æ•°ï¼Œå»ºè®®0.02-0.05
    parse_bonus: float = 0.1,            # è§£ææˆåŠŸå¥–åŠ±
    invalid_penalty: float = -0.5,       # æ— æ•ˆæ ·æœ¬æƒ©ç½š
    # ğŸ”¥ ç‰©ç†ä¸€è‡´æ€§å¥–åŠ±å¼€å…³ï¼ˆé»˜è®¤å…³é—­ï¼‰
    enable_physics_reward: bool = False,  # æ˜¯å¦å¯ç”¨ç‰©ç†ä¸€è‡´æ€§å¥–åŠ±
    # ğŸ”¥ è¿‡ç¨‹å¥–åŠ±å¼€å…³ï¼ˆé»˜è®¤å¼€å¯ï¼‰
    enable_process_reward: bool = True,   # æ˜¯å¦å¯ç”¨çœŸè¿‡ç¨‹å¥–åŠ±
) -> None:
    # ğŸ”¥ ä¿®å¤è¾“å‡ºç›®å½•å‘½åï¼Œä½¿å…¶ä¸v1ç‰ˆæœ¬ä¸€è‡´åŒ…å«æ—¶é—´æˆ³
    import time
    from datetime import datetime
    
    # ä»data_pathæå–é—®é¢˜åç§°
    problem_name = "unknown"
    if "oscillator1" in data_path:
        problem_name = "oscillator1"
    elif "oscillator2" in data_path:
        problem_name = "oscillator2"
    elif "bactgrow" in data_path:
        problem_name = "bactgrow"
    elif "stressstrain" in data_path:
        problem_name = "stressstrain"
    
    # ç”Ÿæˆæ—¶é—´æˆ³
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ğŸ”¥ ä½¿ç”¨ä¸v1ä¸€è‡´çš„å‘½åæ ¼å¼ï¼š{problem}_qwen8b_v2_{timestamp}
    if output_dir.endswith("_v2") or output_dir.endswith("/oscillator1_v2"):
        # å¦‚æœä¼ å…¥çš„æ˜¯ç®€å•çš„v2ç›®å½•ï¼Œåˆ™ç”Ÿæˆå®Œæ•´çš„å¸¦æ—¶é—´æˆ³çš„ç›®å½•å
        base_dir = os.path.dirname(output_dir) if "/" in output_dir else "./llmsr_grpo_outputs"
        output_dir = os.path.join(base_dir, f"{problem_name}_qwen8b_v2_{timestamp}")
        print(f"ğŸ”¥ V2è¾“å‡ºç›®å½•å·²æ›´æ–°ä¸º: {output_dir}")
    
    os.makedirs(output_dir, exist_ok=True)
    memory_dir = os.path.join(output_dir, "memory_v2")
    os.makedirs(memory_dir, exist_ok=True)

    # 1) æ•°æ®é›†
    dataset_path = create_llmsr_dataset_v2(
        template_path=template_path,
        data_path=data_path,
        output_dir=output_dir,
        memory_dir=memory_dir,
        grid_train_data=grid_train_data,
        num_grid_groups=num_grid_groups,
        few_shot_k=few_shot_k,
        num_islands=num_islands,
        top_k_per_island=top_k_per_island,
    )

    # 2) å¥–åŠ±æ–‡ä»¶
    reward_file_path = create_llmsr_reward_file_v2(
        template_path=template_path,
        data_path=data_path,
        output_dir=output_dir,
        memory_dir=memory_dir,
        grid_train_data=grid_train_data,
        length_penalty_alpha=length_penalty_alpha,
        parse_bonus=parse_bonus,
        invalid_penalty=invalid_penalty,
        enable_physics_reward=enable_physics_reward,
        enable_process_reward=enable_process_reward,
        num_islands=num_islands,
        top_k_per_island=top_k_per_island,
        # ğŸ”¥ ä¼ é€’æ•°æ®é›†åˆ·æ–°å‚æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰
        refresh_manager_config={
            "output_dir": output_dir,
            "refresh_params": {
                "current_dataset_path": dataset_path,
                "template_path": template_path,
                "data_path": data_path,
                "memory_dir": memory_dir,
                "grid_train_data": grid_train_data,
                "num_grid_groups": num_grid_groups,
                "few_shot_k": few_shot_k,
                "num_islands": num_islands,
                "top_k_per_island": top_k_per_island,
            }
        }
    )

    # 3) é…ç½®
    config = create_grpo_config_v2(
        model_path=model_path,
        dataset_path=dataset_path,
        reward_file_path=reward_file_path,
        output_dir=output_dir,
        gpus=gpus,
        rollout_n=rollout_n,
        kl_coef=kl_coef,
        max_prompt_length=max_prompt_length,
        max_new_tokens=max_new_tokens,
        max_model_len=max_model_len,
        max_num_batched_tokens=max_num_batched_tokens,
        learning_rate=learning_rate,
        epochs=epochs,
    )

    # 4) è®­ç»ƒ
    cfg_path = os.path.join(output_dir, "grpo_config_v2.yaml")
    OmegaConf.save(config, cfg_path)
    # è®©å¥–åŠ±å‡½æ•°èƒ½å†™å…¥æ ·æœ¬æ–‡ä»¶
    os.environ["LLMSR_OUTPUT_DIR"] = output_dir
    run_ppo(config)

    # 5) è®­ç»ƒç»“æŸåï¼Œä» sample.jsonl ä¸­é€‰å‡ºæœ€ä¼˜
    try:
        import json
        best_reward = None
        best_mse = None
        best_reward_rec = None
        best_mse_rec = None
        jsonl_path = os.path.join(output_dir, "sample.jsonl")
        if os.path.exists(jsonl_path):
            with open(jsonl_path, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        rec = json.loads(line)
                    except Exception:
                        continue
                    r = rec.get("reward")
                    # ğŸ”¥ ä¼˜å…ˆä½¿ç”¨mseï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨nmseï¼ˆå…¼å®¹v1å’Œv2æ ¼å¼ï¼‰
                    m = rec.get("mse") or rec.get("nmse")
                    if isinstance(r, (int, float)) and (best_reward is None or r > best_reward):
                        best_reward = r
                        best_reward_rec = rec
                    if isinstance(m, (int, float)) and (best_mse is None or m < best_mse):
                        best_mse = m
                        best_mse_rec = rec
        if best_reward_rec:
            with open(os.path.join(output_dir, "best_reward.json"), "w", encoding="utf-8") as f:
                json.dump(best_reward_rec, f, ensure_ascii=False, indent=2)
        if best_mse_rec:
            with open(os.path.join(output_dir, "best_mse.json"), "w", encoding="utf-8") as f:
                json.dump(best_mse_rec, f, ensure_ascii=False, indent=2)
    except Exception:
        pass