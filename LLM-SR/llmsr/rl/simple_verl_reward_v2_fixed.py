#!/usr/bin/env python3
"""
ğŸ”¥ ä¿®å¤ç‰ˆVERLå¥–åŠ±å‡½æ•° V2 - é‡‡ç”¨æ— RLç‰ˆæœ¬çš„æ­£ç¡®æ–¹æ³• + å¤šæˆåˆ†å¥–åŠ±

å…³é”®æ”¹è¿›ï¼š
1. ä¸å†æå–æ•°å­¦è¡¨è¾¾å¼å­—ç¬¦ä¸²
2. ç›´æ¥æ‰§è¡ŒLLMç”Ÿæˆçš„å®Œæ•´Pythonå‡½æ•°
3. ä¿æŒV2ç‰ˆæœ¬çš„å¤šæˆåˆ†å¥–åŠ±è®¡ç®—
4. æ¨¡ä»¿æ— RLç‰ˆæœ¬çš„å¤„ç†æµç¨‹
"""

import math
import re
from typing import Any, Dict, List, Tuple
import numpy as np
import os, json, time
import ast
import pandas as pd
from pathlib import Path


def compute_score(
    data_sources=None,  # ç§»é™¤ç±»å‹æ³¨è§£ï¼Œä¿æŒä¸v1ç‰ˆæœ¬ä¸€è‡´
    solution_strs=None,
    ground_truths=None,
    extra_infos=None,
    # ç§»é™¤ * ä½¿æ‰€æœ‰å‚æ•°éƒ½å¯ä»¥ä½ç½®ä¼ é€’ï¼ŒåŒæ—¶ä¹Ÿæ”¯æŒå…³é”®å­—ä¼ é€’
    grid_train_data=False,
    template_path=None,
    data_path=None,
    memory_dir=None,
    lambda_nmse=3.0,
    lambda_simp=0.1,
    w_fit=0.75,
    w_simp=0.2,
    w_phys=0.15,
    w_proc=0.05,
    groupwise_rank_norm=True,
    # ğŸ”¥ æ–°å¢é•¿åº¦æƒ©ç½šå’Œè§£æå¥–åŠ±å‚æ•°
    length_penalty_alpha=0.03,  # é•¿åº¦æƒ©ç½šç³»æ•°ï¼Œå»ºè®®0.02-0.05
    parse_bonus=0.1,            # è§£ææˆåŠŸå¥–åŠ±
    invalid_penalty=-0.5,       # æ— æ•ˆæ ·æœ¬æƒ©ç½š
    # ğŸ”¥ ç‰©ç†ä¸€è‡´æ€§å¥–åŠ±å¼€å…³ï¼ˆé»˜è®¤å…³é—­ï¼‰
    enable_physics_reward=False,  # æ˜¯å¦å¯ç”¨ç‰©ç†ä¸€è‡´æ€§å¥–åŠ±
    # ğŸ”¥ è¿‡ç¨‹å¥–åŠ±ç³»ç»Ÿå¼€å…³å’Œå‚æ•°
    enable_process_reward=True,  # æ˜¯å¦å¯ç”¨çœŸè¿‡ç¨‹å¥–åŠ±ï¼ˆé»˜è®¤å¼€å¯ï¼‰
    process_reward_weights=None, # è¿‡ç¨‹å¥–åŠ±å„æˆåˆ†æƒé‡ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼
    # ğŸï¸ ç¾¤å²›æœºåˆ¶è¶…å‚æ•°
    num_islands=4,              # ç¾¤å²›æ•°é‡
    top_k_per_island=8,         # æ¯ä¸ªå²›å±¿ä¿å­˜çš„topæ ·æœ¬æ•°
    # ğŸ”¥ æ•°æ®é›†åˆ·æ–°ç®¡ç†å™¨é…ç½®
    refresh_manager_config=None, # æ•°æ®é›†åˆ·æ–°ç®¡ç†å™¨é…ç½®
    **kwargs,
):
    print(f"ğŸ”¥ğŸ”¥ğŸ”¥ FIXED V2 REWARD FUNCTION CALLED! ğŸ”¥ğŸ”¥ğŸ”¥")
    print(f"ğŸ”§ V2ä¿®å¤ç‰ˆå‚æ•°ç±»å‹: data_sources={type(data_sources)}, solution_strs={type(solution_strs)}, ground_truths={type(ground_truths)}, extra_infos={type(extra_infos)}")
    print(f"ğŸ”§ V2 kwargs: {list(kwargs.keys())}")
    print(f"ğŸ”§ V2 Solution strings count: {len(solution_strs) if solution_strs else 0}")
    if solution_strs and len(solution_strs) > 0:
        print(f"ğŸ”§ V2 First solution preview: {solution_strs[0][:200] if solution_strs[0] else 'None'}...")
    print(f"ğŸ”§ V2 LLMSR_OUTPUT_DIR env: {os.environ.get('LLMSR_OUTPUT_DIR', 'NOT_SET')}")
    
    # ğŸ”¥ å…¼å®¹v1ç‰ˆæœ¬çš„å‚æ•°å¤„ç†æ–¹å¼
    # å°è¯•ä»kwargsä¸­æå–æ•°æ®ï¼ˆå…¼å®¹VERLçš„ä¸åŒè°ƒç”¨æ–¹å¼ï¼‰
    if not solution_strs and 'responses' in kwargs:
        solution_strs = kwargs['responses']
        print(f"ğŸ”§ V2 ä»kwargs['responses']è·å–solution_strs: {len(solution_strs) if solution_strs else 0}ä¸ª")
    if not solution_strs and 'generated_texts' in kwargs:
        solution_strs = kwargs['generated_texts']
        print(f"ğŸ”§ V2 ä»kwargs['generated_texts']è·å–solution_strs: {len(solution_strs) if solution_strs else 0}ä¸ª")
    if not extra_infos and 'batch' in kwargs:
        extra_infos = [{'problem_type': 'oscillator1'}]  # é»˜è®¤é—®é¢˜ç±»å‹
        print(f"ğŸ”§ V2 ä½¿ç”¨é»˜è®¤extra_infos: {extra_infos}")
    
    # ğŸ”¥ é‡è¦ï¼šå¤„ç†VERLçš„å•æ•°å½¢å¼å‚æ•°ï¼ˆæ¥è‡ªv1ç‰ˆæœ¬çš„ç»éªŒï¼‰
    if not solution_strs and 'solution_str' in kwargs:
        solution_strs = [kwargs['solution_str']]  # è½¬æ¢ä¸ºåˆ—è¡¨
        print(f"ğŸ”§ V2 ä»kwargs['solution_str']è·å–å•ä¸ªsolution")
    if not data_sources and 'data_source' in kwargs:
        data_sources = [kwargs['data_source']]
    if not ground_truths and 'ground_truth' in kwargs:
        ground_truths = [kwargs['ground_truth']]
    if not extra_infos and 'extra_info' in kwargs:
        extra_infos = [kwargs['extra_info']]
    
    # ğŸ”¥ è°ƒè¯•ï¼šæ£€æŸ¥æ‰€æœ‰å‚æ•°æ˜¯å¦ä¸ºNoneçš„æƒ…å†µ
    if data_sources is None and solution_strs is None and ground_truths is None and extra_infos is None:
        print("âš ï¸ V2 æ‰€æœ‰å‚æ•°éƒ½ä¸ºNoneï¼Œè¿™é€šå¸¸å‘ç”Ÿåœ¨VERLéªŒè¯é˜¶æ®µï¼Œè¿”å›é»˜è®¤æ ‡é‡å€¼")
        return 0.0
    
    # ğŸ”¥ è¾“å…¥å…œåº• - ä¸v1ç‰ˆæœ¬ä¿æŒä¸€è‡´
    solution_strs = solution_strs or []
    extra_infos = extra_infos or [{} for _ in range(len(solution_strs))]
    if len(solution_strs) == 0:
        print("âš ï¸ V2 æ²¡æœ‰è§£å†³æ–¹æ¡ˆå­—ç¬¦ä¸²ï¼Œè¿”å›é»˜è®¤å€¼ 0.0")
        return 0.0  # ğŸ”¥ è¿”å›æ ‡é‡è€Œä¸æ˜¯ç©ºåˆ—è¡¨ï¼Œä¸v1ç‰ˆæœ¬ä¸€è‡´

    # ğŸ”¥ ä¿®å¤ï¼šä¼˜å…ˆä»extra_infosæå–problem_typeï¼ˆä¸v1ç‰ˆæœ¬ä¸€è‡´ï¼‰
    problem_type = None
    if extra_infos and len(extra_infos) > 0 and extra_infos[0]:
        if isinstance(extra_infos[0], dict):
            problem_type = extra_infos[0].get('problem_type')
            if not problem_type and 'extra_info' in extra_infos[0]:
                # å¤„ç†åµŒå¥—çš„extra_info
                nested_info = extra_infos[0]['extra_info']
                if isinstance(nested_info, dict):
                    problem_type = nested_info.get('problem_type')
    
    print(f"ğŸ”§ V2 æå–çš„problem_type: {problem_type}")
    
    # å¦‚æœæ²¡æœ‰æä¾›data_pathï¼Œå°è¯•ä»problem_typeæ„å»ºè·¯å¾„
    if not data_path and problem_type:
        data_path = f"data/{problem_type}/train.csv"
        print(f"ğŸ”§ V2 ä»problem_typeæ„å»ºdata_path: {data_path}")
    
    # åŠ è½½æ•°æ®ï¼ˆä½¿ç”¨å…¨éƒ¨æ ·æœ¬ï¼‰
    inputs, outputs, var_names = _load_training_data_from_path(data_path)
    if inputs is None:
        # ğŸ”¥ å¦‚æœä»data_pathåŠ è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨v1ç‰ˆæœ¬çš„load_training_dataæ–¹æ³•
        print(f"âš ï¸ V2 ä»data_pathåŠ è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨v1ç‰ˆæœ¬çš„æ–¹æ³•")
        train_data = load_training_data_v1(problem_type)
        if train_data is not None:
            inputs, outputs, var_names = train_data
    
    if inputs is None:
        # ğŸ”¥ è¿”å›æƒ©ç½š - ä¸v1ç‰ˆæœ¬ä¿æŒä¸€è‡´çš„è¿”å›å€¼å¤„ç†
        print(f"âŒ V2 æ— æ³•åŠ è½½è®­ç»ƒæ•°æ®ï¼Œè¿”å›æƒ©ç½šå€¼")
        if len(solution_strs) == 1:
            return 0.0  # å•ä¸ªæ ·æœ¬è¿”å›æ ‡é‡
        else:
            return [float(-1.0)] * len(solution_strs)  # å¤šä¸ªæ ·æœ¬è¿”å›åˆ—è¡¨

    # è®¡ç®—å„é¡¹ reward
    out_dir = os.environ.get("LLMSR_OUTPUT_DIR")
    jsonl_path = None
    if out_dir:
        try:
            os.makedirs(out_dir, exist_ok=True)
            jsonl_path = os.path.join(out_dir, "sample.jsonl")
        except Exception:
            jsonl_path = None

    # ğŸ”¥ åˆå§‹åŒ–memoryç®¡ç†å™¨ï¼ˆç”¨äºæ›´æ–°memoryï¼‰- V2æ”¹è¿›ç‰ˆï¼šè‡ªé€‚åº”åˆ†ä½æ•°
    memory_manager = None
    
    # ğŸ”¥ ç®€åŒ–ï¼šå‡†å¤‡æ•°æ®é›†åˆ·æ–°å‚æ•°ï¼ˆä»…åœ¨éœ€è¦æ—¶ä½¿ç”¨ï¼‰
    dataset_refresh_params = None
    if refresh_manager_config and isinstance(refresh_manager_config, dict):
        refresh_params = refresh_manager_config.get("refresh_params", {})
        if refresh_params:
            dataset_refresh_params = refresh_params.copy()
            dataset_refresh_params["output_dir"] = out_dir or refresh_manager_config.get("output_dir", "./")
    
    if memory_dir and os.path.exists(memory_dir):
        try:
            # å¯¼å…¥MemoryManagerV2ï¼ˆéœ€è¦ç¡®ä¿è·¯å¾„æ­£ç¡®ï¼‰
            import sys
            sys.path.append("/storage/home/westlakeLab/zhangjunlei/llm_sr_rl/LLM-SR")
            from llmsr.rl.grpo_runner_v2 import MemoryManagerV2, refresh_dataset_with_islands
            
            # ğŸ”¥ V2æ”¹è¿›ç‰ˆï¼šæ·»åŠ è‡ªé€‚åº”å‚æ•°
            memory_manager = MemoryManagerV2(
                memory_dir, 
                top_k_per_island=top_k_per_island, 
                num_islands=num_islands,
                update_frequency=50,  # æ¯50ä¸ªæ ·æœ¬æ›´æ–°ä¸€æ¬¡é˜ˆå€¼
                recent_samples_window=200  # åŸºäºæœ€è¿‘200ä¸ªæ ·æœ¬è®¡ç®—åˆ†ä½æ•°
            )
            print(f"âœ… V2 æˆåŠŸåˆå§‹åŒ–è‡ªé€‚åº”memoryç®¡ç†å™¨: {memory_dir} (å²›å±¿:{num_islands}, æ¯å²›top-k:{top_k_per_island}, è‡ªé€‚åº”æ›´æ–°)")
            print(f"ğŸ”„ æ•°æ®é›†åˆ·æ–°é˜ˆå€¼: æ¯{memory_manager._dataset_refresh_threshold}ä¸ªæ–°ç¾¤å²›æ ·æœ¬è§¦å‘ä¸€æ¬¡åˆ·æ–°")
            
        except Exception as e:
            print(f"âš ï¸ V2 memoryç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            memory_manager = None

    rewards: List[float] = []
    for i, code in enumerate(solution_strs):
        base_impl = None
        if i < len(extra_infos) and isinstance(extra_infos[i], dict):
            base_impl = extra_infos[i].get("base_impl")

        # æ”¯æŒ EDIT DSLï¼šè‹¥åŒ…å« EDIT æŒ‡ä»¤åˆ™åŸºäº base_impl ç”Ÿæˆè¡¨è¾¾å¼
        edit_mode = False
        
        # ğŸ”¥ ä½¿ç”¨æ–°çš„æ–¹æ³•ï¼šç›´æ¥æ‰§è¡ŒPythonå‡½æ•°
        base_reward, execution_success, mse, complexity, params_used, opt_info = evaluate_single_solution_v2_fixed(
            code, inputs, outputs, var_names, lambda_nmse, lambda_simp, w_fit, w_simp, w_phys, w_proc, 
            enable_physics_reward, enable_process_reward, process_reward_weights
        )
        
        # ğŸ”¥ è®¡ç®—é•¿åº¦æƒ©ç½šï¼šreward := base_reward - Î±Â·(len_tokens/1k)
        len_tokens = _estimate_token_length(code)
        length_penalty = length_penalty_alpha * (len_tokens / 1000.0)
        
        # ğŸ”¥ è§£æå¥–åŠ±å’Œæ— æ•ˆæƒ©ç½š
        if execution_success:
            parse_reward = parse_bonus  # è§£ææˆåŠŸå¥–åŠ±
        else:
            parse_reward = invalid_penalty  # æ— æ•ˆæ ·æœ¬æƒ©ç½š
        
        # ğŸ”¥ æœ€ç»ˆå¥–åŠ± = åŸºç¡€å¥–åŠ± - é•¿åº¦æƒ©ç½š + è§£æå¥–åŠ±/æƒ©ç½š
        final_reward = base_reward - length_penalty + parse_reward
        
        rewards.append(float(final_reward))

        # ğŸ”¥ è®°å½•æ ·æœ¬åˆ°sample.jsonlï¼ˆæ¨¡ä»¿v1ç‰ˆæœ¬æ ¼å¼ï¼‰
        if jsonl_path:
            try:
                # ğŸ”¥ æå–å‡½æ•°ä½“ç”¨äºè®°å½•ï¼ˆæ¨¡ä»¿v1ç‰ˆæœ¬ï¼‰
                function_body = extract_function_body_v2(code)
                
                rec = {
                    "solution_length": len(code) if code else 0,  # ğŸ”¥ v1ç‰ˆæœ¬å­—æ®µ
                    "timestamp": time.time(),
                    "execution_success": execution_success,  # ğŸ”¥ v1ç‰ˆæœ¬å­—æ®µ
                    "function_body": function_body,  # ğŸ”¥ v1ç‰ˆæœ¬å­—æ®µ
                    "params": params_used.tolist() if params_used is not None else None,  # ğŸ”¥ v1ç‰ˆæœ¬å­—æ®µ
                    "mse": float(mse) if mse is not None else None,  # ğŸ”¥ v1ç‰ˆæœ¬å­—æ®µ
                    "reward": float(final_reward),  # ğŸ”¥ v1ç‰ˆæœ¬å­—æ®µ
                    "error": None if execution_success else "æ‰§è¡Œå¤±è´¥",  # ğŸ”¥ v1ç‰ˆæœ¬å­—æ®µ
                    # ğŸ”¥ v2ç‰ˆæœ¬é¢å¤–å­—æ®µ
                    "base_reward": float(base_reward),
                    "length_penalty": float(length_penalty),
                    "parse_reward": float(parse_reward),
                    "len_tokens": int(len_tokens),
                    "nmse": float(mse / (np.var(outputs) + 1e-9)) if mse is not None and mse < 1e6 and outputs is not None else None,
                    "complexity": float(complexity) if complexity is not None else None,
                    "r_fit": None,
                    "r_simp": None,
                    "r_phys": None,
                    "r_proc": None,
                    "edit_mode": edit_mode,
                    "ast_ok": execution_success,
                    "data_path": data_path,
                }
                
                # ğŸ”¥ æ·»åŠ è¿‡ç¨‹å¥–åŠ±è¯¦æƒ…ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if enable_process_reward and opt_info is not None:
                    rec["process_reward_details"] = {
                        "optimizer_success": opt_info.get('success', False),
                        "iterations": opt_info.get('nit', 0),
                        "initial_loss": opt_info.get('initial_loss'),
                        "final_loss": opt_info.get('final_loss'),
                        "improvement": opt_info.get('improvement'),
                        "grad_norm": opt_info.get('grad_norm'),
                        "params_norm": opt_info.get('params_norm'),
                        "has_nan_inf": opt_info.get('has_nan_inf', False),
                        "enabled": True
                    }
                else:
                    rec["process_reward_details"] = {"enabled": False}
                with open(jsonl_path, "a", encoding="utf-8") as f:
                    f.write(json.dumps(rec, ensure_ascii=False) + "\n")
            except Exception as e:
                print(f"âš ï¸ è®°å½•sample.jsonlå¤±è´¥: {e}")
                pass

        # ğŸ”¥ V2æ”¹è¿›ç‰ˆï¼šæ›´åˆç†çš„è¿›å²›é—¨æ§› - å…è®¸æ‰§è¡ŒæˆåŠŸçš„æ ·æœ¬éƒ½è¿›å…¥ï¼Œè®©è‡ªé€‚åº”åˆ†ä½æ•°æœºåˆ¶å……åˆ†å‘æŒ¥
        if memory_manager and execution_success:  # åªè¦æ‰§è¡ŒæˆåŠŸå°±è€ƒè™‘å…¥åº“
            try:
                function_body = extract_function_body_v2(code)
                if function_body:  # ç¡®ä¿å‡½æ•°ä½“ä¸ä¸ºç©º
                    # ğŸ”¥ è°ƒç”¨add_sampleå¹¶æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°æ•°æ®é›†
                    need_refresh = memory_manager.add_sample(
                        function_body=function_body,
                        score=final_reward,
                        mse=mse,
                        complexity=complexity
                    )
                    print(f"ğŸ¯ V2 æˆåŠŸæ·»åŠ æ ·æœ¬åˆ°memoryï¼Œscore: {final_reward:.3f}")
                    
                    # ğŸ”¥ å¦‚æœéœ€è¦åˆ·æ–°æ•°æ®é›†ï¼Œç«‹å³æ‰§è¡Œ
                    if need_refresh and dataset_refresh_params:
                        try:
                            print(f"ğŸ”„ è§¦å‘æ•°æ®é›†åˆ·æ–°ï¼ˆæ–°æ ·æœ¬æ•°>=8ï¼‰...")
                            
                            # è·å–å½“å‰æ•°æ®é›†è·¯å¾„
                            current_dataset = dataset_refresh_params.get("current_dataset_path")
                            if current_dataset and os.path.exists(current_dataset):
                                new_dataset_path = refresh_dataset_with_islands(
                                    dataset_path=current_dataset,
                                    template_path=dataset_refresh_params.get("template_path"),
                                    data_path=dataset_refresh_params.get("data_path"),
                                    memory_dir=memory_dir,
                                    output_dir=dataset_refresh_params["output_dir"],
                                    grid_train_data=dataset_refresh_params.get("grid_train_data", False),
                                    num_grid_groups=dataset_refresh_params.get("num_grid_groups", 10),
                                    few_shot_k=dataset_refresh_params.get("few_shot_k", 3),
                                    num_islands=num_islands,
                                    top_k_per_island=top_k_per_island,
                                )
                                
                                if new_dataset_path != current_dataset:
                                    print(f"âœ… æ•°æ®é›†åˆ·æ–°å®Œæˆ: {new_dataset_path}")
                                    # ğŸ”¥ åˆ›å»ºä¿¡å·æ–‡ä»¶ï¼Œé€šçŸ¥å¯èƒ½çš„å¤–éƒ¨ç›‘æ§
                                    signal_file = os.path.join(dataset_refresh_params["output_dir"], "dataset_refreshed.signal")
                                    with open(signal_file, "w") as f:
                                        json.dump({
                                            "timestamp": time.time(),
                                            "new_dataset_path": new_dataset_path,
                                            "trigger": "new_samples_threshold_reached",
                                            "new_samples_count": 8
                                        }, f, indent=2)
                                
                        except Exception as refresh_e:
                            print(f"âŒ æ•°æ®é›†åˆ·æ–°å¤±è´¥: {refresh_e}")
            except Exception as e:
                print(f"âš ï¸ V2 æ·»åŠ æ ·æœ¬åˆ°memoryå¤±è´¥: {e}")
                pass

    # ç»„å†…æ’åå½’ä¸€ï¼ˆè‹¥ VERL æ‰¹æ¬¡æ¥è‡ªåŒä¸€æç¤ºç»„ï¼Œå¯é™ä½å°ºåº¦å™ªå£°ï¼‰
    if groupwise_rank_norm and len(rewards) >= 2:
        order = np.argsort(rewards)[::-1]
        ranks = np.empty_like(order)
        ranks[order] = np.arange(len(rewards))
        rewards = (1.0 - ranks / max(1, len(rewards) - 1)).astype(np.float32).tolist()

    # ğŸ”¥ VERL å…¼å®¹ï¼šè¿”å›å€¼å¤„ç†ä¸v1ç‰ˆæœ¬ä¿æŒä¸€è‡´
    if not rewards:
        print("âš ï¸ V2 æ²¡æœ‰è®¡ç®—å‡ºå¥–åŠ±ï¼Œè¿”å›é»˜è®¤å€¼ 0.0")
        return 0.0
    
    # ğŸ”¥ å¤„ç†å•ä¸ªæ ·æœ¬çš„æƒ…å†µï¼ˆVERLéªŒè¯æ—¶ç»å¸¸å¦‚æ­¤ï¼‰
    if len(rewards) == 1:
        reward_value = float(rewards[0])
        print(f"ğŸ¯ V2 è¿”å›å•ä¸ªå¥–åŠ±å€¼: {reward_value}")
        return reward_value
    
    # å¤šä¸ªæ ·æœ¬çš„æƒ…å†µ
    rewards_array = np.array(rewards, dtype=np.float32)
    print(f"ğŸ¯ V2 è¿”å›å¥–åŠ±æ•°ç»„ï¼Œé•¿åº¦: {len(rewards_array)}")
    return rewards_array.tolist()


def evaluate_single_solution_v2_fixed(
    solution_str: str, 
    inputs: np.ndarray, 
    outputs: np.ndarray, 
    var_names: list,
    lambda_nmse: float = 3.0,
    lambda_simp: float = 0.1,
    w_fit: float = 0.6,
    w_simp: float = 0.2,
    w_phys: float = 0.15,
    w_proc: float = 0.05,
    enable_physics_reward: bool = False,
    enable_process_reward: bool = True,
    process_reward_weights: dict = None
):
    """
    ğŸ”¥ V2ä¿®å¤ç‰ˆï¼šä½¿ç”¨æ— RLç‰ˆæœ¬çš„æ–¹æ³•ç›´æ¥æ‰§è¡ŒPythonå‡½æ•° + å¤šæˆåˆ†å¥–åŠ±
    
    Returns:
        reward, execution_success, mse, complexity, params_used, opt_info
    """
    
    try:
        # ğŸ”¥ æ­¥éª¤1ï¼šä»LLMè¾“å‡ºä¸­æå–å‡½æ•°ä½“
        function_body = extract_function_body_v2(solution_str)
        
        if not function_body:
            print(f"âŒ V2å‡½æ•°ä½“æå–å¤±è´¥")
            return -1.0, False, 1e6, 0.0, None, None
        
        print(f"âœ… V2æˆåŠŸæå–å‡½æ•°ä½“ï¼Œé•¿åº¦: {len(function_body)}")
        
        # ğŸ”¥ æ­¥éª¤2ï¼šæ„å»ºå®Œæ•´çš„å¯æ‰§è¡Œç¨‹åº
        program = build_executable_program_v2(function_body, var_names)
        
        # ğŸ”¥ æ­¥éª¤3ï¼šåœ¨å®‰å…¨ç¯å¢ƒä¸­æ‰§è¡Œç¨‹åºå¹¶è®¡ç®—MSE
        mse, params_used, opt_info = execute_and_compute_mse_v2(program, inputs, outputs, var_names)
        
        if mse >= 1e6:
            return -1.0, False, mse, 0.0, params_used, opt_info
        
        # è®¡ç®—NMSE
        var_y = float(np.var(outputs) + 1e-9)
        nmse = mse / var_y
        
        # è®¡ç®—å„é¡¹å¥–åŠ±
        r_fit = math.exp(-lambda_nmse * nmse)
        
        # ä¼°ç®—å¤æ‚åº¦ï¼ˆåŸºäºå‡½æ•°ä½“é•¿åº¦ï¼‰
        complexity = _estimate_complexity_from_body(function_body)
        r_simp = math.exp(-lambda_simp * complexity)
        
        # ç‰©ç†ä¸€è‡´æ€§ï¼ˆå¯é€‰ï¼Œé»˜è®¤å…³é—­ï¼‰
        if enable_physics_reward:
            r_phys = _physical_consistency_v2(function_body, var_names, inputs, outputs)
        else:
            r_phys = 1.0  # é»˜è®¤ä¸æƒ©ç½š
            w_phys = 0.0  # æƒé‡è®¾ä¸º0ï¼Œä¸å½±å“æ€»å¥–åŠ±
        
        # ğŸ”¥ è¿‡ç¨‹å¥–åŠ±ï¼šçœŸæ­£çš„è¿‡ç¨‹ç›‘ç£ vs å ä½å¼
        if enable_process_reward and opt_info is not None:
            # çœŸæ­£çš„è¿‡ç¨‹å¥–åŠ±ï¼šåŸºäºä¼˜åŒ–å™¨çŠ¶æ€
            r_proc = _compute_true_process_reward(
                opt_info, mse, nmse, complexity, process_reward_weights
            )
        else:
            # å ä½å¼è¿‡ç¨‹å¥–åŠ±ï¼ˆå‘åå…¼å®¹ï¼‰
            r_proc = 0.5 if mse < 1.0 else 0.0
        
        # ç»¼åˆå¥–åŠ±
        reward = w_fit * r_fit + w_simp * r_simp + w_phys * r_phys + w_proc * r_proc
        
        print(f"âœ… V2è®¡ç®—å®Œæˆ - MSE: {mse:.6f}, å¥–åŠ±: {reward:.6f}")
        
        return reward, True, mse, complexity, params_used, opt_info
        
    except Exception as e:
        print(f"âŒ V2æ‰§è¡ŒPythonå‡½æ•°æ—¶å‡ºé”™: {e}")
        return -1.0, False, 1e6, 0.0, None, None


class _FunctionLineVisitorV2(ast.NodeVisitor):
    """ V2ç‰ˆæœ¬ï¼šVisitor that finds the last line number of a function with a given name."""

    def __init__(self, target_function_name: str) -> None:
        self._target_function_name: str = target_function_name
        self._function_end_line: int | None = None

    def visit_FunctionDef(self, node: Any) -> None: 
        """ Collect the end line number of the target function."""
        if node.name == self._target_function_name:
            self._function_end_line = node.end_lineno
        self.generic_visit(node)

    @property
    def function_end_line(self) -> int:
        """ Line number of the final line of function `target_function_name`."""
        assert self._function_end_line is not None 
        return self._function_end_line


def _trim_function_body_v2(generated_code: str) -> str:
    """ V2ç‰ˆæœ¬ï¼šExtract the body of the generated function, trimming anything after it.
    Please note that the indentation is REQUIRED !!!
    """
    if not generated_code:
        return ''

    code = f'def fake_function_header():\n{generated_code}'

    tree = None
    while tree is None:
        try:
            tree = ast.parse(code)
        
        except SyntaxError as e:
            if e.lineno is None: # Nothing could be saved when syntaxError
                return ''
            code = '\n'.join(code.splitlines()[:e.lineno - 1])

    if not code:
        return ''

    visitor = _FunctionLineVisitorV2('fake_function_header')
    visitor.visit(tree)
    body_lines = code.splitlines()[1:visitor.function_end_line]
    return '\n'.join(body_lines) + '\n\n'


def extract_function_body_v2(solution_str: str) -> str:
    """V2ç‰ˆæœ¬ï¼šä»LLMè¾“å‡ºä¸­æå–å‡½æ•°ä½“ï¼Œæ”¹è¿›å¤„ç†å„ç§æ ¼å¼"""
    if not solution_str or not isinstance(solution_str, str):
        return ""
    
    # å¤„ç†<think>æ ‡ç­¾
    if "</think>" in solution_str:
        parts = solution_str.split("</think>")
        if len(parts) > 1:
            solution_str = parts[-1].strip()
    
    # ğŸ”¥ æ”¹è¿›ï¼šä¼˜å…ˆæŸ¥æ‰¾å®Œæ•´çš„å‡½æ•°å®šä¹‰
    lines = solution_str.splitlines()
    
    # é¦–å…ˆå°è¯•æ‰¾åˆ°å®Œæ•´çš„å‡½æ•°å®šä¹‰ï¼ˆdef equation...åˆ°å‡½æ•°ä½“ç»“æŸï¼‰
    func_start = -1
    func_end = -1
    in_function = False
    func_indent = None
    
    for i, line in enumerate(lines):
        stripped = line.strip()
        
        # æŸ¥æ‰¾å‡½æ•°å®šä¹‰å¼€å§‹
        if stripped.startswith("def equation") and ":" in stripped:
            func_start = i
            in_function = True
            func_indent = len(line) - len(line.lstrip())
            continue
        
        # å¦‚æœåœ¨å‡½æ•°å†…éƒ¨
        if in_function and line.strip():
            current_indent = len(line) - len(line.lstrip())
            # å¦‚æœç¼©è¿›å°äºæˆ–ç­‰äºå‡½æ•°å®šä¹‰çš„ç¼©è¿›ï¼Œè¯´æ˜å‡½æ•°ç»“æŸ
            if current_indent <= func_indent:
                func_end = i
                break
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å‡½æ•°ç»“æŸï¼Œè®¾ç½®åˆ°æœ€å
    if func_start >= 0 and func_end == -1:
        func_end = len(lines)
    
    # å¦‚æœæ‰¾åˆ°äº†å®Œæ•´çš„å‡½æ•°å®šä¹‰ï¼Œæå–å‡½æ•°ä½“
    if func_start >= 0 and func_end > func_start:
        func_lines = lines[func_start+1:func_end]
        # è¿‡æ»¤æ‰EDITæŒ‡ä»¤ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        body_lines = []
        for line in func_lines:
            if not line.strip().startswith("EDIT"):
                body_lines.append(line)
        
        # å¦‚æœæœ‰å‡½æ•°ä½“å†…å®¹
        if body_lines:
            # è§„èŒƒåŒ–ç¼©è¿›
            normalized_body = []
            for line in body_lines:
                if line.strip():
                    # ç¡®ä¿ç¼©è¿›ä¸º4ä¸ªç©ºæ ¼
                    normalized_body.append('    ' + line.lstrip())
                else:
                    normalized_body.append('')
            
            body_str = '\n'.join(normalized_body) + '\n\n'
            print(f"âœ… V2æˆåŠŸæå–å®Œæ•´å‡½æ•°ä½“ï¼Œé•¿åº¦: {len(body_str)}")
            return body_str
    
    # ğŸ”¥ å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œæ•´å‡½æ•°ï¼Œå°è¯•å¤„ç†EDIT DSLæ ¼å¼
    if "EDIT ADD" in solution_str:
        edit_terms = []
        
        for line in lines:
            line_stripped = line.strip()
            # æ”¶é›†EDIT ADDæŒ‡ä»¤
            if line_stripped.startswith("EDIT ADD"):
                term = line_stripped.replace("EDIT ADD", "").strip()
                edit_terms.append(term)
        
        # å¦‚æœæ‰¾åˆ°äº†EDITæŒ‡ä»¤ï¼Œæ„å»ºå‡½æ•°ä½“
        if edit_terms:
            # æ„å»ºreturnè¯­å¥ï¼Œæ­£ç¡®å¤„ç†è¿ç®—ç¬¦é—´è·
            # å°†è¿ç»­çš„é¡¹ç”¨åŠ å·è¿æ¥ï¼ˆå¦‚æœé¡¹æœ¬èº«ä¸æ˜¯ä»¥è¿ç®—ç¬¦å¼€å§‹ï¼‰
            return_parts = []
            for term in edit_terms:
                # å¦‚æœé¡¹ä»¥è¿ç®—ç¬¦å¼€å§‹ï¼ˆå¦‚ -params[0]ï¼‰ï¼Œç›´æ¥æ·»åŠ 
                if term.startswith(('+', '-')):
                    if return_parts:  # å¦‚æœä¸æ˜¯ç¬¬ä¸€é¡¹ï¼Œæ·»åŠ ç©ºæ ¼
                        return_parts.append(' ')
                    return_parts.append(term)
                else:
                    # å¦åˆ™æ·»åŠ åŠ å·
                    if return_parts:
                        return_parts.append(' + ')
                    return_parts.append(term)
            
            return_expr = ''.join(return_parts)
            function_body = f"    return {return_expr}\n\n"
            print(f"âœ… V2æˆåŠŸä»EDIT DSLæ„å»ºå‡½æ•°ä½“: {return_expr}")
            return function_body
    
    # ğŸ”¥ å¦‚æœå‰é¢çš„æ–¹æ³•éƒ½å¤±è´¥äº†ï¼ŒæŸ¥æ‰¾Pythonä»£ç å—
    import re
    code_block_patterns = [
        r'```python\s*\n(.*?)\n```',
        r'```\s*\n(.*?)\n```'
    ]
    
    code_block_content = None
    for pattern in code_block_patterns:
        matches = re.findall(pattern, solution_str, re.DOTALL)
        if matches:
            code_block_content = matches[0]
            break
    
    # å¦‚æœæ‰¾åˆ°ä»£ç å—ï¼Œé€’å½’è°ƒç”¨è‡ªå·±å¤„ç†ä»£ç å—å†…å®¹
    if code_block_content:
        print(f"ğŸ” V2åœ¨ä»£ç å—ä¸­æŸ¥æ‰¾å‡½æ•°ä½“")
        return extract_function_body_v2(code_block_content)
    
    # ğŸ”¥ å®Œå…¨æ¨¡ä»¿sampler.pyçš„_extract_bodyé€»è¾‘
    lines = solution_str.splitlines()
    func_body_lineno = 0
    find_def_declaration = False
    
    for lineno, line in enumerate(lines):
        # find the first 'def' program statement in the response
        # ğŸ”¥ æ”¹è¿›ï¼šå¤„ç†å¯èƒ½çš„å‰å¯¼ç©ºæ ¼
        stripped_line = line.lstrip()
        if stripped_line.startswith('def equation'):  # æ›´å…·ä½“çš„åŒ¹é…
            func_body_lineno = lineno
            find_def_declaration = True
            break
        elif line[:3] == 'def':  # ğŸ”¥ ä¿ç•™åŸå§‹çš„ç²¾ç¡®åŒ¹é…ä½œä¸ºåå¤‡
            func_body_lineno = lineno
            find_def_declaration = True
            break
    
    if find_def_declaration:
        # ğŸ”¥ æ”¹è¿›ï¼šæ›´æ™ºèƒ½åœ°å¤„ç†å‡½æ•°ä½“
        # ä»å‡½æ•°å®šä¹‰çš„ä¸‹ä¸€è¡Œå¼€å§‹æ”¶é›†å‡½æ•°ä½“
        body_lines = []
        base_indent = None
        
        for i in range(func_body_lineno + 1, len(lines)):
            line = lines[i]
            
            # è·³è¿‡ç©ºè¡Œ
            if not line.strip():
                continue
            
            # æ£€æµ‹åŸºç¡€ç¼©è¿›çº§åˆ«
            if base_indent is None and line.strip():
                # è®¡ç®—ç¬¬ä¸€ä¸ªéç©ºè¡Œçš„ç¼©è¿›
                base_indent = len(line) - len(line.lstrip())
            
            # å¦‚æœé‡åˆ°ç¼©è¿›çº§åˆ«å°äºåŸºç¡€ç¼©è¿›çš„è¡Œï¼Œè¯´æ˜å‡½æ•°ä½“ç»“æŸ
            if base_indent is not None and line.strip():
                current_indent = len(line) - len(line.lstrip())
                if current_indent < base_indent:
                    break
            
            body_lines.append(line)
        
        # æ„å»ºå‡½æ•°ä½“
        if body_lines:
            # è§„èŒƒåŒ–ç¼©è¿›ä¸º4ä¸ªç©ºæ ¼
            normalized_lines = []
            for line in body_lines:
                if line.strip():  # éç©ºè¡Œ
                    # ç§»é™¤åŸæœ‰ç¼©è¿›ï¼Œæ·»åŠ æ ‡å‡†4ç©ºæ ¼ç¼©è¿›
                    normalized_lines.append('    ' + line.lstrip())
                else:
                    normalized_lines.append('')
            
            function_body = '\n'.join(normalized_lines) + '\n'
            return function_body
        
    # ğŸ”¥ å¦‚æœä¸Šè¿°æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•ç®€å•çš„returnè¯­å¥æå–
    # è¿™æ˜¯ä¸ºäº†å¤„ç†æŸäº›æƒ…å†µä¸‹å‡½æ•°ä½“ç›´æ¥ä½œä¸ºå­—ç¬¦ä¸²è¿”å›
    for line in lines:
        stripped = line.strip()
        if stripped.startswith('return '):
            # æå–returnè¯­å¥
            return_expr = stripped[7:]  # ç§»é™¤ 'return '
            function_body = f"    return {return_expr}\n"
            print(f"âœ… V2ä»returnè¯­å¥æå–å‡½æ•°ä½“: {function_body.strip()}")
            return function_body
    
    # ğŸ”¥ å¦‚æœéƒ½å¤±è´¥äº†ï¼Œæ£€æŸ¥æ˜¯å¦æ•´ä¸ªå­—ç¬¦ä¸²å°±æ˜¯ä¸€ä¸ªç®€å•çš„è¡¨è¾¾å¼
    # å»é™¤ç©ºç™½è¡Œåï¼Œå¦‚æœå‰©ä½™å†…å®¹çœ‹èµ·æ¥åƒä¸€ä¸ªPythonè¡¨è¾¾å¼ï¼Œç›´æ¥ä½œä¸ºreturnè¯­å¥
    non_empty_lines = [line.strip() for line in lines if line.strip()]
    if non_empty_lines and len(non_empty_lines) <= 3:  # ç®€å•è¡¨è¾¾å¼é€šå¸¸ä¸è¶…è¿‡3è¡Œ
        # æ£€æŸ¥æ˜¯å¦åŒ…å«Pythonè¿ç®—ç¬¦æˆ–å‡½æ•°è°ƒç”¨
        expr_text = ' '.join(non_empty_lines)
        if any(op in expr_text for op in ['+', '-', '*', '/', '**', 'np.', 'math.', 'params[']):
            function_body = f"    return {expr_text}\n"
            print(f"âœ… V2å°†è¡¨è¾¾å¼ä½œä¸ºå‡½æ•°ä½“: {function_body.strip()}")
            return function_body
    
    print(f"âš ï¸ V2å‡½æ•°ä½“æå–å¤±è´¥ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ã€‚åŸå§‹å†…å®¹é•¿åº¦: {len(solution_str)}")
    return ""  # ğŸ”¥ ä¿æŒè¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œè¿™æ ·å¯ä»¥æ˜ç¡®çŸ¥é“æå–å¤±è´¥


def build_executable_program_v2(function_body: str, var_names: list) -> str:
    """V2ç‰ˆæœ¬ï¼šæ„å»ºå®Œæ•´çš„å¯æ‰§è¡Œç¨‹åº"""
    
    # æ„å»ºå‡½æ•°ç­¾å
    params_str = ', '.join(var_names) + ', params'
    
    # ğŸ”¥ ä½¿ç”¨å­—ç¬¦ä¸²æ‹¼æ¥è€Œä¸æ˜¯f-stringï¼Œé¿å…æ ¼å¼åŒ–é—®é¢˜
    program_template = """
import numpy as np
import math
from scipy.optimize import minimize

def equation(PARAMS_PLACEHOLDER):
FUNCTION_BODY_PLACEHOLDER

def evaluate_function(inputs, outputs, var_names):
    '''V2ç‰ˆæœ¬ï¼šè¯„ä¼°å‡½æ•°æ€§èƒ½ - ä½¿ç”¨BFGSä¼˜åŒ–å‚æ•°ï¼Œè¿”å›è¯¦ç»†ä¼˜åŒ–ä¿¡æ¯'''
    try:
        # è®°å½•åˆå§‹MSEï¼ˆç”¨éšæœºå‚æ•°ï¼‰
        initial_params = np.ones(10)
        
        def loss_function(params):
            try:
                # ğŸ”¥ æŒ‰ç…§æ— RLç‰ˆæœ¬çš„æ–¹å¼ï¼Œç›´æ¥ä¼ é€’æ•´ä¸ªæ•°ç»„
                if len(var_names) == 2:  # x, v (oscillator)
                    x_data = inputs[:, 0]
                    v_data = inputs[:, 1] 
                    predictions = equation(x_data, v_data, params)
                elif len(var_names) == 4:  # b, s, temp, pH (bactgrow)
                    b_data = inputs[:, 0]
                    s_data = inputs[:, 1]
                    temp_data = inputs[:, 2]
                    pH_data = inputs[:, 3]
                    predictions = equation(b_data, s_data, temp_data, pH_data, params)
                elif len(var_names) == 2 and 'strain' in var_names:  # strain, temp (stressstrain)
                    strain_data = inputs[:, 0]
                    temp_data = inputs[:, 1]
                    predictions = equation(strain_data, temp_data, params)
                else:
                    # é€šç”¨å¤„ç†ï¼šä¼ é€’æ‰€æœ‰åˆ—ä½œä¸ºå‚æ•°
                    args = [inputs[:, j] for j in range(inputs.shape[1])]
                    predictions = equation(*args, params)
                
                # ç¡®ä¿predictionsæ˜¯numpyæ•°ç»„
                predictions = np.asarray(predictions, dtype=np.float64)
                
                # å¤„ç†æ ‡é‡è¿”å›å€¼
                if predictions.ndim == 0:
                    predictions = np.full_like(outputs, float(predictions))
                
                # è®¡ç®—MSE
                mse = np.mean((predictions - outputs) ** 2)
                return float(mse) if np.isfinite(mse) else 1e6
                
            except Exception as e:
                return 1e6
        
        # è®¡ç®—åˆå§‹æŸå¤±
        initial_loss = loss_function(initial_params)
        
        # ğŸ”¥ BFGSå‚æ•°ä¼˜åŒ–ï¼ˆæ¨¡ä»¿æ— RLç‰ˆæœ¬ï¼‰
        result = minimize(loss_function, initial_params, method='BFGS', options={'maxiter': 100})
        
        # è·å–ä¼˜åŒ–åçš„å‚æ•°å’ŒæŸå¤±
        optimized_params = result.x
        optimized_loss = result.fun
        
        # æ„å»ºä¼˜åŒ–ä¿¡æ¯å­—å…¸
        opt_info = {
            'success': result.success,
            'nit': result.nit,  # è¿­ä»£æ¬¡æ•°
            'initial_loss': float(initial_loss),
            'final_loss': float(optimized_loss),
            'improvement': float((initial_loss - optimized_loss) / (initial_loss + 1e-9)),
            'message': result.message if hasattr(result, 'message') else '',
            'grad_norm': float(np.linalg.norm(result.jac)) if hasattr(result, 'jac') and result.jac is not None else None,
            'params_norm': float(np.linalg.norm(optimized_params)),
            'has_nan_inf': bool(np.any(np.isnan(optimized_params)) or np.any(np.isinf(optimized_params)))
        }
        
        # å¤„ç†ä¼˜åŒ–å¤±è´¥çš„æƒ…å†µ
        if np.isnan(optimized_loss) or np.isinf(optimized_loss) or not result.success:
            print("âš ï¸ V2 BFGSä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
            optimized_params = initial_params
            optimized_loss = loss_function(initial_params)
            opt_info['success'] = False
            opt_info['final_loss'] = float(optimized_loss)
        
        return float(optimized_loss), optimized_params, opt_info
        
    except Exception as e:
        print("âŒ V2å‡½æ•°æ‰§è¡Œé”™è¯¯: " + str(e))
        return 1e6, np.ones(10), None
"""
    
    # å®‰å…¨æ›¿æ¢å ä½ç¬¦
    program = program_template.replace("PARAMS_PLACEHOLDER", params_str)
    program = program.replace("FUNCTION_BODY_PLACEHOLDER", function_body)
    
    return program


def execute_and_compute_mse_v2(program: str, inputs: np.ndarray, outputs: np.ndarray, var_names: list) -> tuple[float, np.ndarray, dict]:
    """V2ç‰ˆæœ¬ï¼šåœ¨å®‰å…¨ç¯å¢ƒä¸­æ‰§è¡Œç¨‹åºå¹¶è®¡ç®—MSEï¼Œè¿”å›ä¼˜åŒ–ä¿¡æ¯"""
    
    try:
        # æ‰§è¡Œç¨‹åº
        all_globals_namespace = {
            'np': np,
            'numpy': np,
            'math': math
        }
        
        # æ·»åŠ scipy.optimize.minimizeåˆ°å‘½åç©ºé—´
        from scipy.optimize import minimize
        all_globals_namespace['minimize'] = minimize
        
        # æ‰§è¡Œç¨‹åº
        exec(program, all_globals_namespace)
        
        # è·å–è¯„ä¼°å‡½æ•°
        evaluate_function = all_globals_namespace['evaluate_function']
        
        # è°ƒç”¨è¯„ä¼°å‡½æ•°ï¼ˆç°åœ¨è¿”å›3ä¸ªå€¼ï¼‰
        result = evaluate_function(inputs, outputs, var_names)
        
        # å¤„ç†è¿”å›å€¼
        if isinstance(result, tuple) and len(result) == 3:
            mse, params_used, opt_info = result
        elif isinstance(result, tuple) and len(result) == 2:
            # å‘åå…¼å®¹ï¼šå¦‚æœåªè¿”å›2ä¸ªå€¼
            mse, params_used = result
            opt_info = None
        else:
            mse = 1e6
            params_used = None
            opt_info = None
        
        return mse, params_used, opt_info
        
    except Exception as e:
        print(f"âŒ V2ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return 1e6, None, None


def load_training_data_v1(problem_type):
    """æ ¹æ®é—®é¢˜ç±»å‹åŠ è½½è®­ç»ƒæ•°æ®ï¼ˆæ¥è‡ªv1ç‰ˆæœ¬ï¼‰"""
    
    if not problem_type:
        print("âš ï¸ V2 é—®é¢˜ç±»å‹æœªçŸ¥ï¼Œå°è¯•ä½¿ç”¨oscillator1ä½œä¸ºé»˜è®¤")
        problem_type = "oscillator1"
    
    # æ•°æ®æ–‡ä»¶è·¯å¾„
    data_file = f"data/{problem_type}/train.csv"
    if not Path(data_file).exists():
        print(f"âŒ V2 æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        return None
    
    try:
        df = pd.read_csv(data_file)
        
        if problem_type == "oscillator1":
            if all(col in df.columns for col in ['x', 'v', 'a']):
                inputs = df[['x', 'v']].values  # ä½¿ç”¨å…¨éƒ¨æ ·æœ¬
                outputs = df['a'].values
                var_names = ['x', 'v']
                return inputs, outputs, var_names
                
        elif problem_type == "oscillator2":
            if all(col in df.columns for col in ['t', 'x', 'v', 'a']):
                inputs = df[['x', 'v']].values  # åªç”¨x,vï¼Œå¿½ç•¥tï¼Œä½¿ç”¨å…¨éƒ¨æ ·æœ¬
                outputs = df['a'].values
                var_names = ['x', 'v']
                return inputs, outputs, var_names
                
        elif problem_type == "bactgrow":
            if all(col in df.columns for col in ['b', 's', 'temp', 'pH', 'db']):
                inputs = df[['b', 's', 'temp', 'pH']].values  # ä½¿ç”¨å…¨éƒ¨æ ·æœ¬
                outputs = df['db'].values
                var_names = ['b', 's', 'temp', 'pH']
                return inputs, outputs, var_names
                
        elif problem_type == "stressstrain":
            if all(col in df.columns for col in ['strain', 'temp', 'stress']):
                inputs = df[['strain', 'temp']].values  # ä½¿ç”¨å…¨éƒ¨æ ·æœ¬
                outputs = df['stress'].values
                var_names = ['strain', 'temp']
                return inputs, outputs, var_names
        
        print(f"âŒ V2 ä¸æ”¯æŒçš„é—®é¢˜ç±»å‹æˆ–æ•°æ®æ ¼å¼: {problem_type}, åˆ—: {list(df.columns)}")
        return None
        
    except Exception as e:
        print(f"âŒ V2 åŠ è½½æ•°æ®æ—¶å‡ºé”™: {e}")
        return None


def _load_training_data_from_path(data_path: str | None) -> Tuple[np.ndarray | None, np.ndarray | None, List[str] | None]:
    if not data_path:
        return None, None, None
    try:
        import pandas as pd
        df = pd.read_csv(data_path)
        data = df.values
        # å‡è®¾æœ€åä¸€åˆ—ä¸ºè¾“å‡ºï¼Œä½¿ç”¨å…¨éƒ¨æ ·æœ¬
        X = data[:, :-1]
        y = data[:, -1].reshape(-1)
        var_names = df.columns[:-1].tolist()
        return X, y, var_names
    except Exception:
        return None, None, None


def _estimate_complexity_from_body(function_body: str) -> float:
    """
    ğŸ”¥ å‡çº§ç‰ˆå¤æ‚åº¦ä¼°è®¡ï¼šAST + å­æ ‘å¤ç”¨ + å¸¸æ•°MDL + åµŒå¥—æ·±åº¦ + åˆ†æ®µ/ä¸å¯å¾®ç»“æ„
    åŸºäºASTåˆ†æè€Œéç®€å•æ­£åˆ™ï¼Œæ›´å‡†ç¡®åæ˜ è¡¨è¾¾å¼çš„ç»“æ„å¤æ‚åº¦
    """
    return estimate_complexity_from_body_v3(function_body)


# â€”â€” åŸºç¡€æƒé‡ï¼ˆå‚ç…§ PySR: è¶…è¶Šå‡½æ•°æ›´è´µï¼‰ â€”â€”
OP_WEIGHTS = {
    'Add': 1.0, 'Sub': 1.0,
    'Mult': 1.5, 'Div': 2.0, 'FloorDiv': 2.0, 'Mod': 2.5,
    'Pow': 3.0,
}
# å¸¸è§æ•°å­¦å‡½æ•°ä»£ä»·ï¼›å¯ç»§ç»­æ‰©å……
FUNC_WEIGHTS = {
    "sin": 2.0, "cos": 2.0, "tan": 3.0,
    "exp": 4.0, "log": 4.0, "sqrt": 3.0, "abs": 2.0, "tanh": 3.0,
    "sinh": 3.0, "cosh": 3.0, "atan": 3.0, "asin": 3.0, "acos": 3.0,
}


def estimate_complexity_from_body_v3(function_body: str) -> float:
    """
    æ›´ç²¾ç»†çš„å¤æ‚åº¦ä¼°è®¡ï¼ˆAST + å­æ ‘å¤ç”¨ + å¸¸æ•°MDL + åµŒå¥—æ·±åº¦ + åˆ†æ®µ/ä¸å¯å¾®ç»“æ„ï¼‰
    è¿”å›æ ‡é‡å¤æ‚åº¦ Cï¼ˆè¶Šå¤§è¶Šå¤æ‚ï¼‰
    """
    if not function_body or not isinstance(function_body, str):
        return 0.0

    # æ„é€ å¯è§£æçš„å‡å‡½æ•°ï¼Œä¿è¯ç¼©è¿›æ­£ç¡®
    code = f"def __eq__(x, y, z, params):\n{function_body}"
    try:
        tree = ast.parse(code)
    except SyntaxError:
        # è¯­æ³•ä¸é€šæ—¶ç»™é«˜å¤æ‚åº¦
        return 100.0

    # æ‰¾åˆ°ç›®æ ‡å‡½æ•°ä½“
    fnode = None
    for n in tree.body:
        if isinstance(n, ast.FunctionDef) and n.name == "__eq__":
            fnode = n
            break
    
    if fnode is None:
        return 100.0

    # â€”â€” çŠ¶æ€å®¹å™¨ â€”â€”
    stats = {
        "op_cost": 0.0,              # åŠ æƒç®—å­æˆæœ¬
        "func_cost": 0.0,            # åŠ æƒå‡½æ•°æˆæœ¬
        "depth_max": 0,              # æœ€å¤§åµŒå¥—æ·±åº¦
        "piecewise_cnt": 0,          # åˆ†æ®µ/ä¸å¯å¾®ç»“æ„å‡ºç°æ¬¡æ•°
        "pow_max_k": 1,              # æœ€å¤§å¹‚é˜¶
        "const_bits": 0.0,           # å¸¸æ•°æè¿°é•¿åº¦ï¼ˆMDL è¿‘ä¼¼ï¼‰
        "unique_subtrees": 0,        # DAG å”¯ä¸€å­æ ‘è®¡æ•°
        "total_subtrees": 0,         # å­æ ‘æ€»æ•°ï¼ˆç”¨äºå¤ç”¨ç‡ä¼°è®¡ï¼‰
        "poly_terms": 0,             # ä¼°ç®—å¤šé¡¹å¼é¡¹æ•°
    }

    # â€”â€” å­æ ‘å“ˆå¸Œï¼šè¡¡é‡ DAG å‹ç¼©æ€§/å”¯ä¸€å­å¼æ•°é‡ â€”â€”
    from collections import defaultdict
    counter = defaultdict(int)
    
    def hash_subtree(n):
        # åŸºäºèŠ‚ç‚¹ç±»å‹ä¸å­ç»“æ„çš„é€’å½’å“ˆå¸Œï¼ˆæ–‡æœ¬åŒ–ï¼‰ï¼›åªåšå¯å‘å¼
        if isinstance(n, ast.Constant) and isinstance(n.value, (int, float)):
            return f"Const({repr(n.value)})"
        elif hasattr(ast, 'Num') and isinstance(n, ast.Num):  # Python < 3.8 å…¼å®¹
            return f"Const({repr(n.n)})"
        
        label = type(n).__name__
        fields = []
        for name, val in ast.iter_fields(n):
            if isinstance(val, ast.AST):
                fields.append((name, hash_subtree(val)))
            elif isinstance(val, list):
                fields.append((name, tuple(hash_subtree(x) for x in val if isinstance(x, ast.AST))))
            elif isinstance(val, (str, int, float, bool, type(None))):
                # ä¸æŠŠè¡Œå·/åˆ—å·ç­‰å…ƒä¿¡æ¯çº³å…¥
                if name not in ("lineno", "col_offset", "end_lineno", "end_col_offset", "id", "arg"):
                    fields.append((name, val))
        key = f"{label}:{tuple(fields)}"
        counter[key] += 1
        return key

    # â€”â€” éå†ï¼šç»Ÿè®¡å„åˆ†é‡ + è®°å½•æ·±åº¦/å¹‚é˜¶/åˆ†æ®µç»“æ„ â€”â€”
    def walk(n, depth=0):
        stats["depth_max"] = max(stats["depth_max"], depth)
        stats["total_subtrees"] += 1
        key = hash_subtree(n)  # è§¦å‘è®¡æ•°

        # äºŒå…ƒç®—å­
        if isinstance(n, ast.BinOp):
            op_name = type(n.op).__name__
            stats["op_cost"] += OP_WEIGHTS.get(op_name, 1.5)
            if isinstance(n.op, ast.Pow):
                # è§£æå¹‚é˜¶ï¼ˆä»…å½“æŒ‡æ•°æ˜¯å¸¸æ•°æ—¶å¯é ï¼‰
                k = _extract_integer_pow(n)
                if k is not None:
                    stats["pow_max_k"] = max(stats["pow_max_k"], k)

        # å‡½æ•°è°ƒç”¨
        if isinstance(n, ast.Call):
            fname = _get_call_name(n)
            if fname:
                stats["func_cost"] += FUNC_WEIGHTS.get(fname, 3.0)

        # åˆ†æ®µ/ä¸å¯å¾®ï¼šif-else, æ¯”è¾ƒ, æ¡ä»¶è¡¨è¾¾å¼, abs()
        if isinstance(n, (ast.If, ast.IfExp, ast.Compare)):
            stats["piecewise_cnt"] += 1
        if isinstance(n, ast.Call):
            fname = _get_call_name(n)
            if fname in ("abs",):
                stats["piecewise_cnt"] += 1

        # å¸¸æ•°çš„ MDL è¿‘ä¼¼
        if isinstance(n, ast.Constant) and isinstance(n.value, (int, float)):
            stats["const_bits"] += _constant_description_bits(n.value)
        elif hasattr(ast, 'Num') and isinstance(n, ast.Num):  # Python < 3.8 å…¼å®¹
            stats["const_bits"] += _constant_description_bits(n.n)

        # é€’å½’å­èŠ‚ç‚¹
        for child in ast.iter_child_nodes(n):
            walk(child, depth + 1)

    for stmt in fnode.body:
        walk(stmt, depth=1)

    # ç»Ÿè®¡å”¯ä¸€å­æ ‘æ•°ï¼ˆDAGï¼‰
    stats["unique_subtrees"] = sum(1 for k, c in counter.items() if c >= 1)

    # ä¼°ç®—å¤šé¡¹å¼é¡¹æ•°ï¼ˆå¯å‘ï¼šæŒ‰ "åŠ æ³•é“¾ + å¹‚è¡¨è¾¾å¼" ç²—ç•¥ä¼°è®¡ï¼‰
    stats["poly_terms"] = _estimate_poly_terms(counter)

    # â€”â€” ç»„åˆå¤æ‚åº¦ï¼ˆæƒé‡å¯è°ƒï¼‰ â€”â€”
    # æ·±åº¦é¢å¤–æƒ©ç½šï¼šæ·±å±‚æ“ä½œåœ¨è®¡ç®—å’Œå¯è§£é‡Šæ€§ä¸Šéƒ½æ›´éš¾
    depth_cost = 0.5 * stats["depth_max"]
    # DAGï¼šå”¯ä¸€å­æ ‘è¶Šå¤šè¶Šå¤æ‚ï¼›å¯ç”¨ "å”¯ä¸€/æ€»æ•°" çš„æ¯”å€¼æ¥åº¦é‡å¯å‹ç¼©æ€§
    if stats["total_subtrees"] > 0:
        dag_ratio = stats["unique_subtrees"] / float(stats["total_subtrees"])
    else:
        dag_ratio = 1.0
    dag_cost = 5.0 * dag_ratio

    # å¹‚é˜¶ã€åˆ†æ®µã€é¡¹æ•°
    pow_cost = 0.3 * max(0, stats["pow_max_k"] - 1)
    piece_cost = 1.5 * stats["piecewise_cnt"]
    terms_cost = 0.2 * stats["poly_terms"]

    # åˆæˆæ€»å¤æ‚åº¦
    C = (
        stats["op_cost"]
        + stats["func_cost"]
        + depth_cost
        + dag_cost
        + 0.05 * stats["const_bits"]  # å¸¸æ•°çš„æè¿°é•¿åº¦ï¼ˆä½æ•°/ç²¾åº¦è¶Šé«˜è¶Šè´µï¼‰
        + pow_cost
        + piece_cost
        + terms_cost
    )
    return float(C)


# â€”â€” è¾…åŠ©ï¼šæå–å‡½æ•°å â€”â€”
def _get_call_name(node):
    """æå–å‡½æ•°è°ƒç”¨çš„åç§°"""
    if isinstance(node.func, ast.Name):
        return node.func.id
    if isinstance(node.func, ast.Attribute):
        return node.func.attr
    return None


# â€”â€” è¾…åŠ©ï¼šæå–å¹‚æŒ‡æ•°ï¼ˆè‹¥ä¸ºæ•´æ•°å¸¸æ•°ï¼‰ â€”â€”
def _extract_integer_pow(binop):
    """æå–å¹‚è¿ç®—çš„æŒ‡æ•°ï¼ˆå¦‚æœæ˜¯æ•´æ•°å¸¸æ•°ï¼‰"""
    if isinstance(binop.op, ast.Pow):
        if isinstance(binop.right, ast.Constant) and isinstance(binop.right.value, (int, float)):
            try:
                k = int(binop.right.value)
                return k if k >= 1 else None
            except Exception:
                return None
        elif hasattr(ast, 'Num') and isinstance(binop.right, ast.Num):  # Python < 3.8 å…¼å®¹
            try:
                k = int(binop.right.n)
                return k if k >= 1 else None
            except Exception:
                return None
    return None


# â€”â€” è¾…åŠ©ï¼šMDL è¿‘ä¼¼ï¼ˆå¸¸æ•°çš„æè¿°é•¿åº¦ï¼Œä½æ•°+æ•°é‡çº§ï¼‰ â€”â€”
def _constant_description_bits(v) -> float:
    """è®¡ç®—å¸¸æ•°çš„æè¿°é•¿åº¦ï¼ˆMDLè¿‘ä¼¼ï¼‰"""
    v = float(v)
    if v == 0.0:
        return 1.0
    # ä½æ•°æƒ©ç½šï¼šå°æ•°çš„æœ‰æ•ˆæ•°å­—è¶Šå¤šè¶Šè´µï¼ˆä»¥åè¿›åˆ¶è¿‘ä¼¼ï¼‰
    s = f"{v:.12g}"  # é™12ä½æœ‰æ•ˆæ•°å­—ï¼Œé¿å…ç§‘å­¦è®¡æ•°æ³•æç«¯
    digits = len(re.sub(r"[^0-9]", "", s))
    # æ•°é‡çº§æƒ©ç½šï¼š|log10(|v|)| è¶Šå¤§è¶Šè´µï¼ˆé˜²è¶…å¤§/è¶…å°å¸¸æ•°ï¼‰
    magnitude = abs(math.log10(abs(v))) if v != 0 else 0.0
    return digits + 2.0 * magnitude


# â€”â€” è¾…åŠ©ï¼šä¼°ç®—å¤šé¡¹å¼é¡¹æ•°ï¼ˆå¯å‘å¼ï¼šåŸºäºå­æ ‘é”®ï¼‰ â€”â€”
def _estimate_poly_terms(subtree_counter) -> int:
    """ä¼°ç®—å¤šé¡¹å¼é¡¹æ•°ï¼ˆå¯å‘å¼æ–¹æ³•ï¼‰"""
    # ç»Ÿè®¡å‡ºç° "Add:" çš„å­æ ‘ä¸ªæ•°ä½œä¸ºé¡¹åˆ†è£‚çš„ç²—ç•¥åº¦é‡
    terms = sum(1 for k in subtree_counter if k.startswith("BinOp:") and "Add" in k)
    return max(0, terms)


def _compute_true_process_reward(
    opt_info: dict, 
    mse: float, 
    nmse: float, 
    complexity: float,
    process_reward_weights: dict = None
) -> float:
    """
    ğŸ”¥ è®¡ç®—çœŸæ­£çš„è¿‡ç¨‹å¥–åŠ±ï¼ˆåŸºäºä¼˜åŒ–å™¨çŠ¶æ€å’Œæ‰§è¡Œè¿‡ç¨‹ï¼‰
    
    åŒ…å«ä»¥ä¸‹æˆåˆ†ï¼š
    1. æ”¶æ•›æŒ‡ç¤º (r_conv): ä¼˜åŒ–å™¨æ˜¯å¦æˆåŠŸæ”¶æ•›
    2. æ”¹è¿›å¹…åº¦ (r_impr): ä»åˆå§‹åˆ°æœ€ç»ˆçš„æ”¹è¿›ç¨‹åº¦
    3. è¿­ä»£æ•ˆç‡ (r_eff): æ”¶æ•›é€Ÿåº¦
    4. æ•°å€¼å¥åº· (r_num): æ— NaN/Infã€å‚æ•°åˆç†
    5. çº¦æŸæ»¡è¶³ (r_cons): MSEé˜ˆå€¼ç­‰çº¦æŸ
    """
    
    # é»˜è®¤æƒé‡
    if process_reward_weights is None:
        process_reward_weights = {
            'conv': 0.3,   # æ”¶æ•›æŒ‡ç¤ºæƒé‡
            'impr': 0.25,  # æ”¹è¿›å¹…åº¦æƒé‡
            'eff': 0.15,   # è¿­ä»£æ•ˆç‡æƒé‡
            'num': 0.2,    # æ•°å€¼å¥åº·æƒé‡
            'cons': 0.1    # çº¦æŸæ»¡è¶³æƒé‡
        }
    
    # 1. æ”¶æ•›æŒ‡ç¤ºå¥–åŠ±
    if opt_info.get('success', False):
        r_conv = 1.0
    else:
        # ä½¿ç”¨sigmoidå¹³æ»‘ï¼ŒåŸºäºæ¢¯åº¦èŒƒæ•°
        grad_norm = opt_info.get('grad_norm', 1e3)
        if grad_norm is not None and np.isfinite(grad_norm):
            # sigmoid(-grad_norm/scale), scale=10ä½¿å¾—grad_norm=10æ—¶çº¦0.27
            r_conv = 1.0 / (1.0 + np.exp(grad_norm / 10.0))
        else:
            r_conv = 0.0
    
    # 2. æ”¹è¿›å¹…åº¦å¥–åŠ±
    initial_loss = opt_info.get('initial_loss', 1e6)
    final_loss = opt_info.get('final_loss', 1e6)
    
    if initial_loss > 0 and final_loss > 0 and initial_loss >= final_loss:
        # log-scale improvement reward
        improvement_ratio = (initial_loss + 1e-9) / (final_loss + 1e-9)
        r_impr = np.clip(np.log(improvement_ratio) / 5.0, 0.0, 1.0)  # log(148)â‰ˆ5 maps to 1.0
    else:
        r_impr = 0.0
    
    # 3. è¿­ä»£æ•ˆç‡å¥–åŠ±
    nit = opt_info.get('nit', 100)
    max_iter = 100  # BFGSé»˜è®¤æœ€å¤§è¿­ä»£
    r_eff = 1.0 - min(1.0, nit / max_iter)
    
    # 4. æ•°å€¼å¥åº·å¥–åŠ±
    has_nan_inf = opt_info.get('has_nan_inf', False)
    params_norm = opt_info.get('params_norm', 0.0)
    
    # åŸºç¡€å¥åº·åˆ†
    r_num_base = 0.0 if has_nan_inf else 1.0
    
    # å‚æ•°èŒƒæ•°æƒ©ç½šï¼ˆè¿‡å¤§çš„å‚æ•°é€šå¸¸ä¸ç¨³å®šï¼‰
    if params_norm > 0:
        # å‚æ•°èŒƒæ•°åœ¨10ä»¥å†…ç»™æ»¡åˆ†ï¼Œè¶…è¿‡100é™åˆ°0.5
        r_num_norm = 1.0 / (1.0 + (params_norm / 50.0) ** 2)
    else:
        r_num_norm = 1.0
    
    r_num = 0.7 * r_num_base + 0.3 * r_num_norm
    
    # 5. çº¦æŸæ»¡è¶³å¥–åŠ±
    # MSEé˜ˆå€¼çº¦æŸ
    if mse < 0.1:
        r_cons_mse = 1.0
    elif mse < 1.0:
        r_cons_mse = 0.8
    elif mse < 10.0:
        r_cons_mse = 0.5
    else:
        r_cons_mse = 0.0
    
    # å¤æ‚åº¦çº¦æŸï¼ˆé¼“åŠ±ç®€å•è§£ï¼‰
    if complexity < 5.0:
        r_cons_comp = 1.0
    elif complexity < 10.0:
        r_cons_comp = 0.7
    elif complexity < 20.0:
        r_cons_comp = 0.4
    else:
        r_cons_comp = 0.1
    
    r_cons = 0.6 * r_cons_mse + 0.4 * r_cons_comp
    
    # ç»¼åˆè¿‡ç¨‹å¥–åŠ±
    r_proc = (
        process_reward_weights['conv'] * r_conv +
        process_reward_weights['impr'] * r_impr +
        process_reward_weights['eff'] * r_eff +
        process_reward_weights['num'] * r_num +
        process_reward_weights['cons'] * r_cons
    )
    
    # æ‰“å°è¯¦ç»†ä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼‰
    print(f"ğŸ”¬ è¿‡ç¨‹å¥–åŠ±è¯¦æƒ…: conv={r_conv:.3f}, impr={r_impr:.3f}, "
          f"eff={r_eff:.3f}, num={r_num:.3f}, cons={r_cons:.3f}, "
          f"æ€»è®¡={r_proc:.3f}")
    
    return float(r_proc)


def _physical_consistency_v2(function_body: str, var_names: List[str], X: np.ndarray, y: np.ndarray) -> float:
    """V2ç‰ˆæœ¬ï¼šç‰©ç†ä¸€è‡´æ€§æ£€æŸ¥"""
    try:
        # ç®€åŒ–çš„ç‰©ç†ä¸€è‡´æ€§æ£€æŸ¥
        if 'log(' in function_body:
            # log éœ€è¦æ­£è¾“å…¥ï¼Œæ£€æŸ¥æ˜¯å¦å¯èƒ½å‡ºç°éæ­£æ•°
            if np.any(X <= 0):
                return 0.6
        return 1.0
    except Exception:
        return 0.2


def _estimate_token_length(
    text: str,
    *,
    # å¯é€‰ï¼šä¼ å…¥çœŸå® tokenizerï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
    hf_tokenizer=None,     # ä¾‹å¦‚ transformers çš„ AutoTokenizer() å®ä¾‹
    tiktoken_encoder=None, # ä¾‹å¦‚ tiktoken.encoding_for_model(...).encode
    tokenizer_encode_fn=None,  # ä»»ä½•å¯è°ƒç”¨çš„ encode å‡½æ•°
    model_family: str = "qwen",  # 'qwen' | 'openai' | 'llama' | 'generic'
) -> int:
    """
    ğŸ”¥ å‡çº§ç‰ˆtokené•¿åº¦ä¼°è®¡ï¼šç²¾ç¡®ä¼˜å…ˆ + å¯å‘å¼å…œåº•
    1) è‹¥æä¾›çœŸå® tokenizerï¼Œç›´æ¥è¿”å›ç²¾ç¡®é•¿åº¦
    2) å¦åˆ™é‡‡ç”¨"ç±»åˆ«åˆ†æ®µ + å­—èŠ‚/4"çš„æ··åˆå¯å‘å¼ï¼ŒæŒ‰æ¨¡å‹å®¶æ—è°ƒç³»æ•°
    """
    
    # ---- 1) ç²¾ç¡®è®¡æ•°ï¼ˆä¼˜å…ˆï¼‰ ----
    if text is None or text == "":
        return 0
    
    # ğŸ”¥ å°è¯•è‡ªåŠ¨åŠ è½½Qwen3-8Bçš„tokenizer
    if hf_tokenizer is None and tiktoken_encoder is None and tokenizer_encode_fn is None:
        hf_tokenizer = _get_qwen_tokenizer()
    
    try:
        # transformers
        if hf_tokenizer is not None and hasattr(hf_tokenizer, "encode"):
            return int(len(hf_tokenizer.encode(text)))
        # tiktoken
        if tiktoken_encoder is not None and hasattr(tiktoken_encoder, "encode"):
            return int(len(tiktoken_encoder.encode(text)))
        # ä»»æ„å¯è°ƒç”¨ encode
        if callable(tokenizer_encode_fn):
            return int(len(tokenizer_encode_fn(text)))
    except Exception as e:
        # è‹¥å¤±è´¥ï¼Œé€€å›å¯å‘å¼
        print(f"âš ï¸ Tokenizerå¤±è´¥ï¼Œä½¿ç”¨å¯å‘å¼ä¼°è®¡: {e}")
        pass

    # ---- 2) æ”¹è¿›å¯å‘å¼ï¼ˆç±»åˆ«åˆ†æ®µ + UTF-8å­—èŠ‚ï¼‰----
    return _estimate_token_length_heuristic(text, model_family)


def _get_qwen_tokenizer():
    """å°è¯•åŠ è½½Qwen3-8Bçš„tokenizer"""
    try:
        from transformers import AutoTokenizer
        # å°è¯•ä»æœ¬åœ°Qwen3-8Bç›®å½•åŠ è½½
        qwen_path = "/storage/home/westlakeLab/zhangjunlei/Qwen3-8B"
        if os.path.exists(qwen_path):
            tokenizer = AutoTokenizer.from_pretrained(qwen_path, trust_remote_code=True)
            print(f"âœ… æˆåŠŸåŠ è½½Qwen3-8B tokenizer: {qwen_path}")
            return tokenizer
    except Exception as e:
        print(f"âš ï¸ æ— æ³•ä» {qwen_path} åŠ è½½Qwen3-8B tokenizer: {e}")
    return None


def _estimate_token_length_heuristic(text: str, model_family: str = "qwen") -> int:
    """
    å¯å‘å¼tokené•¿åº¦ä¼°è®¡ï¼šç±»åˆ«åˆ†æ®µ + UTF-8å­—èŠ‚æ··åˆæ¨¡å‹
    """
    if not text:
        return 0
    
    # 2.1 ç±»åˆ«åˆ’åˆ†ï¼ˆå°½é‡äº’æ–¥ï¼‰
    # CJK ç»Ÿä¸€è¡¨æ„ & æ‰©å±•ã€å‡åã€éŸ©æ–‡éŸ³èŠ‚
    re_cjk = re.compile(r"[\u3400-\u4DBF\u4E00-\u9FFF\uF900-\uFAFF\u3040-\u30FF\uAC00-\uD7A3]")
    # è¿‘ä¼¼ Emoji / è¡¨æƒ…ç¬¦ï¼ˆè¦†ç›–å¸¸è§åŒºæ®µï¼‰
    re_emoji = re.compile(r"[\U0001F000-\U0001FAFF\U00002702-\U000027B0]")
    # URL / Emailï¼ˆURL å…ˆè¡ŒåŒ¹é…ï¼Œé¿å…è¢«æŒ‰è¯æ‹†æ•£ï¼‰
    re_url  = re.compile(r"https?://[^\s]+|www\.[^\s]+")
    re_mail = re.compile(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}")
    # æ•°å­—ï¼ˆå«å°æ•°/ç§‘å­¦è®¡æ•°ï¼‰
    re_num  = re.compile(r"[+-]?(?:\d+\.\d+|\d+\.|\.\d+|\d+)(?:[eE][+-]?\d+)?")
    # ä»£ç /æ“ä½œç¬¦ä¸²
    re_ops  = re.compile(r"[+\-*/=<>!%&|^~]+")
    # è›‡å½¢/é©¼å³°è¯ï¼ˆä¼˜å…ˆæŠ“é•¿è¯ï¼Œé¿å…è¿‡åº¦åˆ‡ç¢ï¼‰
    re_word = re.compile(r"[A-Za-z]+(?:[_\-][A-Za-z0-9]+)*|[A-Za-z][a-z0-9]+(?:[A-Z][a-z0-9]+)+")
    # å…¶å®ƒå¯è§ ASCII æ ‡ç‚¹
    re_punc = re.compile(r"[.,;:!?â€¦â€”â€“()\[\]{}\<>\"'`""''#@$]")
    # ç©ºç™½
    re_space = re.compile(r"\s+")

    text_remaining = text

    def _pop_all(pattern):
        nonlocal text_remaining
        items = pattern.findall(text_remaining)
        text_remaining = pattern.sub(" ", text_remaining)  # ç”¨ç©ºæ ¼å ä½ï¼Œé¿å…è¿é”å½±å“
        return items

    urls  = _pop_all(re_url)
    mails = _pop_all(re_mail)
    nums  = _pop_all(re_num)
    opss  = _pop_all(re_ops)
    words = _pop_all(re_word)
    # å…ˆå¼¹å‡º emojiï¼Œå†åŒ¹é… CJKï¼ˆé¿å…é‡å¤è®¡æ•°ï¼‰
    emojis = _pop_all(re_emoji)
    cjks   = _pop_all(re_cjk)
    puncs  = _pop_all(re_punc)
    spaces = _pop_all(re_space)

    # å‰©ä½™é›¶æ•£å­—ç¬¦ï¼ˆæ··åˆï¼šå¯èƒ½æ˜¯ç¨€æœ‰ç¬¦å·ã€æ§åˆ¶ç¬¦ç­‰ï¼‰
    leftovers = [c for c in text_remaining if not c.isspace()]

    # 2.2 æ¨¡å‹å®¶æ—ç³»æ•°ï¼ˆå¯æŒ‰ç»éªŒ/æ ‡å®šå¾®è°ƒï¼‰
    if model_family.lower() in ("qwen", "qwen2", "qwen3"):
        coef = dict(
            en_char_per_tok = 4.0,   # è‹±æ–‡ï¼š4å­—ç¬¦/Token
            digit_char_per_tok = 3.0,# æ•°å­—ï¼š3å­—ç¬¦/Token
            cjk_tok_per_char = 0.65, # ä¸­æ–‡æ—¥æ–‡éŸ©æ–‡ï¼š~0.6â€“0.8 Token/å­—ï¼ˆQwen BPE å¸¸è§åŒºé—´ï¼‰
            url_char_per_tok = 3.0,  # URL æ›´ç¢ï¼š3å­—ç¬¦/Token
            mail_char_per_tok= 3.2,  # Email
            ops_char_per_tok = 2.0,  # æ“ä½œç¬¦ï¼š2å­—ç¬¦/Token
            punc_char_per_tok= 2.5,  # æ ‡ç‚¹ï¼š2.5å­—ç¬¦/Token
            space_char_per_tok=10.0, # ç©ºç™½ï¼š10å­—ç¬¦/Tokenï¼ˆå¤§å¤šå¹¶å…¥ç›¸é‚» token çš„å‰å¯¼ç©ºæ ¼ï¼‰
            emoji_tok_per_char=1.3,  # emojiï¼š1.3 Token/å­—ç¬¦
            leftover_char_per_tok=3.2,
            mix_byte_weight = 0.30,  # ä¸"å­—èŠ‚/4"èåˆçš„æƒé‡
        )
    elif model_family.lower() in ("openai", "gpt", "o"):
        coef = dict(
            en_char_per_tok = 4.0,
            digit_char_per_tok = 2.8,
            cjk_tok_per_char = 1.0,  # tiktoken ä¸Šä¸­æ–‡æ›´æ¥è¿‘ 1 Token/å­—
            url_char_per_tok = 2.6,
            mail_char_per_tok= 2.8,
            ops_char_per_tok = 1.8,
            punc_char_per_tok= 2.2,
            space_char_per_tok=12.0,
            emoji_tok_per_char=1.6,
            leftover_char_per_tok=3.0,
            mix_byte_weight = 0.35,
        )
    else:  # 'llama'/'generic' å…œåº•
        coef = dict(
            en_char_per_tok = 4.0,
            digit_char_per_tok = 3.0,
            cjk_tok_per_char = 0.9,
            url_char_per_tok = 2.8,
            mail_char_per_tok= 3.0,
            ops_char_per_tok = 2.0,
            punc_char_per_tok= 2.5,
            space_char_per_tok=10.0,
            emoji_tok_per_char=1.5,
            leftover_char_per_tok=3.2,
            mix_byte_weight = 0.30,
        )

    # 2.3 å­ç±»ä¼°è®¡ï¼ˆæŠŠ"å­—ç¬¦/æ¯Token"æˆ–"Token/å­—ç¬¦"ç»Ÿä¸€æ¢ç®—æˆ Token è®¡æ•°ï¼‰
    # è‹±æ–‡è¯æŒ‰å­—ç¬¦æ•°ä¼°è®¡ï¼ˆæ‹¼åˆè›‡å½¢/é©¼å³°åæ›´æ¥è¿‘çœŸå® BPEï¼‰
    en_chars = sum(len(w) for w in words)
    tokens_en   = en_chars / coef["en_char_per_tok"]
    tokens_num  = sum(len(s) for s in nums)  / coef["digit_char_per_tok"]
    tokens_url  = sum(len(s) for s in urls)  / coef["url_char_per_tok"]
    tokens_mail = sum(len(s) for s in mails) / coef["mail_char_per_tok"]
    tokens_ops  = sum(len(s) for s in opss)  / coef["ops_char_per_tok"]
    tokens_punc = sum(len(s) for s in puncs) / coef["punc_char_per_tok"]
    tokens_space= sum(len(s) for s in spaces)/ coef["space_char_per_tok"]
    tokens_cjk  = sum(len(s) for s in cjks)  * coef["cjk_tok_per_char"]
    tokens_emoji= sum(len(s) for s in emojis)* coef["emoji_tok_per_char"]
    tokens_left = len(leftovers) / coef["leftover_char_per_tok"]

    est_class = (
        tokens_en + tokens_num + tokens_url + tokens_mail +
        tokens_ops + tokens_punc + tokens_space + tokens_cjk +
        tokens_emoji + tokens_left
    )

    # 2.4 å­—èŠ‚/4 èåˆï¼ˆtiktoken æ–‡æ¡£ç»éªŒï¼šå¹³å‡æ¯ Token ~4å­—èŠ‚ï¼‰
    est_bytes = len(text.encode("utf-8")) / 4.0
    mix_w = float(coef["mix_byte_weight"])
    est = (1.0 - mix_w) * est_class + mix_w * est_bytes

    # 2.5 ä¿æŠ¤æ€§çº¦æŸï¼ˆé¿å…æç«¯ä½ä¼°/é«˜ä¼°ï¼‰
    # - Token ä¸å¯èƒ½è¶…è¿‡"å¯è§å­—ç¬¦æ•° * 2"ï¼ˆæç«¯ç¢è£‚ä¸Šé™ï¼Œå®½æ¾ï¼‰
    # - ä¹Ÿä¸åº”å°äº"éç©ºå­—ç¬¦æ•° / 8"ï¼ˆæç«¯åˆå¹¶ä¸‹é™ï¼Œå®½æ¾ï¼‰
    nonspace = len([c for c in text if not c.isspace()])
    upper = 2.0 * nonspace + 16  # åŠ å¸¸æ•°é¡¹åº”å¯¹å¾ˆçŸ­æ–‡æœ¬
    lower = max(1.0, nonspace / 8.0)
    est = max(lower, min(est, upper))

    return int(math.ceil(est))