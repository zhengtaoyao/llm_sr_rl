#!/usr/bin/env bash
# ---------------------------------
# Launch Qwen 1.5B LLM Engine
# Using GPU 0,1 (å‰ä¸¤å¼ å¡)
# ---------------------------------

# ğŸ”§ ç¯å¢ƒé…ç½®
export CUDA_VISIBLE_DEVICES=0,1          # ä½¿ç”¨å‰ä¸¤å¼ å¡
export PORT_LLM=5000
export HF_TOKEN=""                        # å¦‚æœéœ€è¦çš„è¯è®¾ç½®HuggingFace token

# æ¿€æ´»ç¯å¢ƒ
source ~/miniconda3/etc/profile.d/conda.sh
conda activate llmsr || { echo "âŒ Failed to activate llmsr environment"; exit 1; }

# åˆ›å»ºæ—¥å¿—ç›®å½•
LOGDIR=./llmsr_logs
mkdir -p "$LOGDIR"

echo "ğŸš€ Starting Qwen 1.5B LLM Engine"
echo "ğŸ¯ Using GPU cards: 0,1"
echo "ğŸ¤– Model: Qwen/Qwen2.5-1.5B-Instruct"
echo "ğŸŒ Port: $PORT_LLM"

# å¯åŠ¨LLMå¼•æ“
nohup python llm_engine/engine.py \
    --model_path "Qwen/Qwen2.5-1.5B-Instruct" \
    --gpu_ids 0 1 \
    --host "0.0.0.0" \
    --port "$PORT_LLM" \
    --temperature 0.8 \
    --max_new_tokens 512 \
    --top_k 30 \
    --top_p 0.9 \
    --do_sample true \
    > "$LOGDIR/engine_qwen1.5b_${PORT_LLM}.log" 2>&1 &

ENGINE_PID=$!
echo "âœ… Qwen 1.5B Engine started (PID=$ENGINE_PID)"
echo "ğŸ“ Log file: $LOGDIR/engine_qwen1.5b_${PORT_LLM}.log"

# ç­‰å¾…æ¨¡å‹åŠ è½½
echo "â³ Waiting for model to load..."
sleep 30

# æµ‹è¯•è¿æ¥
echo "ğŸ” Testing engine connection..."
if curl -s http://localhost:$PORT_LLM/ > /dev/null; then
    echo "âœ… Engine is responding on port $PORT_LLM"
else
    echo "âŒ Engine not responding. Check logs:"
    echo "   tail -f $LOGDIR/engine_qwen1.5b_${PORT_LLM}.log"
fi

echo "ğŸ¯ Engine ready for GRPO training!"
echo "ğŸ’¡ To stop the engine: kill $ENGINE_PID"