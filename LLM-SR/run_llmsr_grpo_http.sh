#!/usr/bin/env bash

# üîß ËÆæÁΩÆÂèØËßÅÁöÑGPUÂç°‰∏∫5Âíå6
export CUDA_VISIBLE_DEVICES=5,6

# Ê£ÄÊü•HTTPÊúçÂä°ÊòØÂê¶ËøêË°å
if ! curl -s http://localhost:5000/ > /dev/null; then
    echo "‚ùå HTTP LLM service not running. Please start it first:"
    echo "   ./run_llmsr_engine.sh"
    exit 1
fi

echo "‚úÖ HTTP LLM service is running"
echo "üöÄ Starting GRPO training with Mixtral HTTP backend..."
echo "üéØ Using GPU cards: 5,6"

PROBLEM_NAME=${PROBLEM_NAME:-oscillator1}

python main.py \
    --use_rl \
    --use_http \
    --problem_name "${PROBLEM_NAME}" \
    --spec_path "./specs/specification_${PROBLEM_NAME}_numpy.txt" \
    --http_url "${HTTP_URL:-http://localhost:5000}" \
    --tokenizer_path "${TOKENIZER_PATH:-mistralai/Mixtral-8x7B-Instruct-v0.1}" \
    --epochs "${EPOCHS:-5}" \
    --batch_size "${BATCH_SIZE:-16}" \
    --learning_rate "${LEARNING_RATE:-1e-6}" \
    --rollout_n "${ROLLOUT_N:-3}" \
    --gpus 2  # üî• ‰øÆÊîπ‰∏∫2Âç°
